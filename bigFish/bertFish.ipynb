{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 3234\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_fraud.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 13265\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_normal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./fish_cleaner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('fraud.txt', 'r')\n",
    "f2 = open('enron.txt', 'r')\n",
    "\n",
    "corpus_one = [item for item in f1]\n",
    "corpus_two = [item for item in f2]\n",
    "\n",
    "fs = split_set(corpus_one)\n",
    "ns = split_enron_set(corpus_two)\n",
    "\n",
    "fraud_set = []\n",
    "norm_set = []\n",
    "\n",
    "for i in range(len(fs)):\n",
    "    fraud_set.append(super_clean(fs[i]))\n",
    "for i in range(len(ns)):\n",
    "    norm_set.append(super_clean(ns[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_set = fraud_set[:6]\n",
    "norm_set = norm_set[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(fraud, norm):\n",
    "    new_set = []\n",
    "    for item in fraud:\n",
    "        t = (item, 'fraud')\n",
    "        new_set.append(t)\n",
    "    for item in norm:\n",
    "        t = (item, 'norm')\n",
    "        new_set.append(t)\n",
    "    return new_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = label(fraud_set,norm_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NECESSARY IMPORTS:\n",
    "#torch\n",
    "#pytorch-pretrained-bert\n",
    "#torchnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0      1\n",
      "0                  FROM:MR. JAMES NGOLA.    URGEN...  fraud\n",
      "1               Dear Friend,  I am Mr. Ben Sulema...  fraud\n",
      "2   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
      "3   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
      "4   Dear sir,    It is with a heart full of hope ...  fraud\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = g\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'fraud': 6, 'norm': 6})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df[1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: \"text\", 1: \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('pos', 'fraud')\n",
    "df = df.replace('neg', 'norm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FROM:MR. JAMES NGOLA.    URGEN...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dear Friend,  I am Mr. Ben Sulema...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dear sir,    It is with a heart full of hope ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   type\n",
       "0                  FROM:MR. JAMES NGOLA.    URGEN...  fraud\n",
       "1               Dear Friend,  I am Mr. Ben Sulema...  fraud\n",
       "2   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
       "3   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
       "4   Dear sir,    It is with a heart full of hope ...  fraud"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df[df['type'] == 'fraud'] \n",
    "df_statire = df[df['type'] == 'norm'] \n",
    "df_statire = df_statire.sample(n=len(df_fake))\n",
    "df = df_statire.append(df_fake)\n",
    "df = df.sample(frac=1, random_state = 24).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.head(5)\n",
    "test_data = df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PRESIDENT/MANAGING DIRECTOR    Dear Sir/Mada...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Here is our forecast   \"</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dear sir,    It is with a heart full of hope ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45. \"          ...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   type\n",
       "0    PRESIDENT/MANAGING DIRECTOR    Dear Sir/Mada...  fraud\n",
       "1             Here is our forecast   \"                 norm\n",
       "2   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
       "3   Dear sir,    It is with a heart full of hope ...  fraud\n",
       "4   Let's shoot for Tuesday at 11:45. \"          ...   norm"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>\"file\",\"message\"</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Dear Friend,  I am Mr. Ben Sulema...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Traveling to have a business meeting takes th...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>test successful. way to go!!!\"</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Randy,   Can you send me a schedule of the sa...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   type\n",
       "7                      \"file\",\"message\"                 norm\n",
       "8                Dear Friend,  I am Mr. Ben Sulema...  fraud\n",
       "9    Traveling to have a business meeting takes th...   norm\n",
       "10       test successful. way to go!!!\"                 norm\n",
       "11   Randy,   Can you send me a schedule of the sa...   norm"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [{'text': text, 'type': type_data } for text in list(train_data['text']) for type_data in list(train_data['type'])]\n",
    "test_data = [{'text': text, 'type': type_data } for text in list(test_data['text']) for type_data in list(test_data['type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
    "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(train_tokens))\n",
    "print(len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'president', '/', 'managing', 'director', 'dear', 'sir', '/', 'madam', ',', 'request', 'for', 'urgent', 'business', 'relationship', 'we', 'are', 'top', 'officials', 'of', 'the', 'federal', 'government', 'of', 'nigeria', 'contract', 'review', 'panel', 'who', 'are', 'interested', 'in', 'import', '##ation', 'of', 'goods', 'into', 'our', 'country', 'and', 'investing', 'abroad', 'with', 'funds', 'which', 'are', 'presently', 'trapped', 'in', 'nigeria', '.', 'in', 'order', 'to', 'commence', 'this', 'business', 'we', 'sol', '##ici', '##t', 'your', 'assistance', ',', 'knowledge', 'and', 'expertise', 'to', 'enable', 'us', 'rec', '##ie', '##ve', 'the', 'said', 'trapped', 'funds', 'abroad', ',', 'for', 'the', 'subsequent', 'purchase', 'and', 'inventory', 'of', 'the', 'goods', 'to', 'be', 'imported', 'and', 'the', 'investment', 'abroad', '.', 'previous', 'military', 'regimes', 'in', 'our', 'country', ',', 'government', 'officials', 'set', 'up', 'companies', 'and', 'awarded', 'themselves', 'contracts', 'which', 'were', 'gross', '##ly', 'over', '-', 'in', '##vo', '##ice', '##d', 'in', 'various', 'ministries', '.', 'the', 'new', 'civilian', 'government', 'now', 'setup', 'a', 'contract', 'review', 'panel', 'which', 'i', 'and', 'my', 'colleagues', 'are', 'members', 'and', 'we', 'have', 'identified', 'a', 'lot', 'of', 'inflated', 'sum', ',', 'due', 'to', 'our', 'position', 'as', 'civil', 'servants', 'and', 'members', 'of', 'this', 'panel', ',', 'we', 'cannot', 'a', '##qui', '##re', 'this', 'money', 'in', 'our', 'names', '.', 'i', 'have', 'therefore', ',', 'been', 'delegate', '##d', 'as', 'a', 'matter', 'of', 'trust', 'by', 'my', 'colleagues', 'of', 'the', 'panel', 'to', 'look', 'for', 'an', 'overs', '##ea', 'partner', 'into', 'whose', 'account', 'the', 'sum', 'of', 'us', '$', '31', ',', '000', '000', ',', '00', '(', 'thirty', '-', 'one', 'million', 'united', 'states', 'dollars', ')', 'will', 'be', 'paid', 'by', 'telegraph', '##ic', 'transfer', '.', 'hence', 'we', 'are', 'writ', '##ting', 'you', 'this', 'letter', '.', '1', '.', '70', '%', 'for', 'us', '(', 'the', 'officials', ')', '2', '.', '20', '%', 'for', 'the', 'foreign', 'pat', '##ner', '(', 'you', ')', '3', '.', '10', '%', 'to', 'be', 'used', 'in', 'settling', 'taxation', 'and', 'local', 'and', 'foreign', 'expenses', '.', 'it', 'is', 'this', '70', '%', 'that', 'we', 'wish', 'to', 'commence', 'the', 'import', '##ation', 'business', 'and', 'the', 'investment', 'abroad', '.', 'please', 'note', 'that', 'this', 'transaction', 'is', '100', '%', 'safe', 'and', 'we', 'hope', 'that', 'the', 'funds', 'can', 'arrive', 'your', 'account', 'in', 'latest', 'ten', '(', '10', ')', 'banking', 'days', 'from', 'the', 'date', 'of', 'rec', '##ie', '##pt', 'of', 'the', 'following', 'information', '.', 'a', 'suitable', 'company', 'name', 'and', 'bank', 'account', '(', 'company', 'or', 'person', '##el', ')', 'into', 'which', 'the', 'funds', 'can', 'be', 'paid', '.', 'the', 'above', 'information', 'will', 'enable', 'us', 'write', 'letters', 'of', 'claim', 'and', 'job', 'description', 'respectively', '.', 'this', 'way', 'we', 'will', 'use', 'your', 'company', \"'\", 's', 'name', 'to', 'apply', 'for', 'payments', 'and', 're', '-', 'award', 'the', 'contract', 'to', 'your', 'company', 'name', '.', 'we', 'are', 'looking', 'f', '##owa', '##rd', 'to', 'doing', 'business', 'with', 'you', 'and', 'sol', '##ici', '##t', 'your', 'confidential', '##ity', 'in', 'this', 'transaction', '.', 'please', 'acknowledge', 'rec', '##ie', '##pt', 'of', 'this', 'letter', 'using', 'this', 'e', '-', 'mail', 'address', '.', 'david', '##ku', '##ta', '##200', '##2', '@', 'yahoo', '.', 'com', 'i', 'await', 'your', 'urgent', 'response', '.', 'best', 'regards', ',', 'david', 'ku', '##ta', 'dear', 'sir', ',', 'i', 'am', 'barrister', 'tun', '##de', 'dos', '##um', '##u', '(', 'san', ')', 'solicitor', 'at', 'law', '.', 'i', 'am', 'the', 'personal', 'attorney', 'to', 'mr', '.', 'eton', 'simon', ',', 'a', 'national', 'of', 'your', 'country', ',', 'who', 'used', 'to', 'work', 'with', 'shell', 'petroleum', 'development', 'company', '(', 'spd', '##c', ')', 'here', 'in', 'nigeria', '.', 'here', 'in', 'after']\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "t1 = []\n",
    "t2 = []\n",
    "\n",
    "for item in train_labels:\n",
    "    if str(item) == 'fraud': t1.append(1)\n",
    "    else: t1.append(0)    \n",
    "\n",
    "        \n",
    "\n",
    "for item in test_labels:\n",
    "    if str(item) == 'fraud': t2.append(1)\n",
    "    else: t2.append(0)        \n",
    "\n",
    "#train_y_step = np.array(train_labels) == 'fake'\n",
    "#test_y_step = np.array(test_labels) == 'fake'\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(len(train_y_step)):\n",
    "    #train_y.append(int(train_y_step[i]))\n",
    "#for i in range(len(test_y_step)):\n",
    "    #test_y.append(int(test_y_step[i]))\n",
    "    \n",
    "train_y = np.array(t1)\n",
    "test_y = np.array(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "    \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=1)\n",
    "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATEMENT BELOW ITERATES THROUGH EACH ITEM IN THE TRAINING DATASET AT ONE EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/25.0 loss: 0.9485976696014404 \n",
      "Epoch:  1\n",
      "1/25.0 loss: 0.9022595286369324 \n",
      "Epoch:  1\n",
      "2/25.0 loss: 0.8845586578051249 \n",
      "Epoch:  1\n",
      "3/25.0 loss: 0.8851230293512344 \n",
      "Epoch:  1\n",
      "4/25.0 loss: 0.8742474436759948 \n",
      "Epoch:  1\n",
      "5/25.0 loss: 0.8312385082244873 \n",
      "Epoch:  1\n",
      "6/25.0 loss: 0.8292135681424823 \n",
      "Epoch:  1\n",
      "7/25.0 loss: 0.793636217713356 \n",
      "Epoch:  1\n",
      "8/25.0 loss: 0.7951389816072252 \n",
      "Epoch:  1\n",
      "9/25.0 loss: 0.8045317590236664 \n",
      "Epoch:  1\n",
      "10/25.0 loss: 0.7953537377444181 \n",
      "Epoch:  1\n",
      "11/25.0 loss: 0.8049680640300115 \n",
      "Epoch:  1\n",
      "12/25.0 loss: 0.8032556955630963 \n",
      "Epoch:  1\n",
      "13/25.0 loss: 0.7851470283099583 \n",
      "Epoch:  1\n",
      "14/25.0 loss: 0.7668418884277344 \n",
      "Epoch:  1\n",
      "15/25.0 loss: 0.7542024962604046 \n",
      "Epoch:  1\n",
      "16/25.0 loss: 0.7707825232954586 \n",
      "Epoch:  1\n",
      "17/25.0 loss: 0.7781277696291605 \n",
      "Epoch:  1\n",
      "18/25.0 loss: 0.7848568997885051 \n",
      "Epoch:  1\n",
      "19/25.0 loss: 0.775133803486824 \n",
      "Epoch:  1\n",
      "20/25.0 loss: 0.7780556962603614 \n",
      "Epoch:  1\n",
      "21/25.0 loss: 0.7663847506046295 \n",
      "Epoch:  1\n",
      "22/25.0 loss: 0.7730974969656571 \n",
      "Epoch:  1\n",
      "23/25.0 loss: 0.7670687312881151 \n",
      "Epoch:  1\n",
      "24/25.0 loss: 0.7595427060127258 \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "bert_clf = BertBinaryClassifier()\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        probas = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.20      0.32        20\n",
      "           1       0.20      0.80      0.32         5\n",
      "\n",
      "   micro avg       0.32      0.32      0.32        25\n",
      "   macro avg       0.50      0.50      0.32        25\n",
      "weighted avg       0.68      0.32      0.32        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(logits, labels)\n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "        \n",
    "print(classification_report(test_y, bert_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
