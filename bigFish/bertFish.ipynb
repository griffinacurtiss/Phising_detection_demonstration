{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 3234\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_fraud.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 13265\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_normal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./fish_cleaner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('fraud.txt', 'r')\n",
    "f2 = open('enron.txt', 'r')\n",
    "\n",
    "corpus_one = [item for item in f1]\n",
    "corpus_two = [item for item in f2]\n",
    "\n",
    "fs = split_set(corpus_one)\n",
    "ns = split_enron_set(corpus_two)\n",
    "\n",
    "fraud_set = []\n",
    "norm_set = []\n",
    "\n",
    "for i in range(len(fs)):\n",
    "    fraud_set.append(super_clean(fs[i]))\n",
    "for i in range(len(ns)):\n",
    "    norm_set.append(super_clean(ns[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_screen(x):        #remove emails from datasets that are less than 512 tokens long. \n",
    "    z = []\n",
    "    for i in range(len(x)):\n",
    "        temp = x[i].split()\n",
    "        if len(temp) >= 512:\n",
    "            z.append(x[i])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of fraud set before 512 token screening: 3234\n",
      "Length of normal set before 512 token screening: 13265\n",
      "\n",
      "\n",
      "Length of fraud set before 512 token screening: 1608\n",
      "Length of normal set before 512 token screening: 1017\n"
     ]
    }
   ],
   "source": [
    "print('Length of fraud set before 512 token screening: {}'.format(len(fraud_set)))\n",
    "print('Length of normal set before 512 token screening: {}'.format(len(norm_set)))\n",
    "\n",
    "fraud_set = bert_screen(fraud_set)\n",
    "norm_set = bert_screen(norm_set)\n",
    "\n",
    "print('\\n')\n",
    "print('Length of fraud set before 512 token screening: {}'.format(len(fraud_set)))\n",
    "print('Length of normal set before 512 token screening: {}'.format(len(norm_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_set = fraud_set[:1000]\n",
    "norm_set = norm_set[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(fraud, norm):\n",
    "    new_set = []\n",
    "    for item in fraud:\n",
    "        t = (item, 'fraud')\n",
    "        new_set.append(t)\n",
    "    for item in norm:\n",
    "        t = (item, 'norm')\n",
    "        new_set.append(t)\n",
    "    return new_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = label(fraud_set,norm_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0      1\n",
      "0                  FROM:MR. JAMES NGOLA.    URGEN...  fraud\n",
      "1               Dear Friend,  I am Mr. Ben Sulema...  fraud\n",
      "2   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
      "3   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
      "4   Dear sir,    It is with a heart full of hope ...  fraud\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = g\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'fraud': 1000, 'norm': 1000})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df[1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: \"text\", 1: \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FROM:MR. JAMES NGOLA.    URGEN...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dear Friend,  I am Mr. Ben Sulema...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dear sir,    It is with a heart full of hope ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   type\n",
       "0                  FROM:MR. JAMES NGOLA.    URGEN...  fraud\n",
       "1               Dear Friend,  I am Mr. Ben Sulema...  fraud\n",
       "2   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
       "3   FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF E...  fraud\n",
       "4   Dear sir,    It is with a heart full of hope ...  fraud"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = df[df['type'] == 'fraud'] \n",
    "df_norm = df[df['type'] == 'norm'] \n",
    "df_norm = df_norm.sample(n=len(df_fraud))\n",
    "df = df_norm.append(df_fraud)\n",
    "df = df.sample(frac=1, random_state = 24).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.head(1500)\n",
    "test_data = df.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(train_data['text'])\n",
    "x2 = np.array(train_data['type'])\n",
    "\n",
    "y1 = np.array(test_data['text'])\n",
    "y2 = np.array(test_data['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = []\n",
    "t2 = []\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    t1.append({'text': x1[i], 'type': x2[i]})\n",
    "    \n",
    "for i in range(len(y1)):\n",
    "    t2.append({'text': y1[i], 'type': y2[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = t1\n",
    "test_data = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
    "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell above tokenizes text sequences of up to 512 tokens, as that is the max input size of BERT.\n",
    "Datapoints posessing less than 512 tokens are \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "test_y = []\n",
    "t1 = []\n",
    "t2 = []\n",
    "\n",
    "for item in train_labels:\n",
    "    if str(item) == 'fraud': t1.append(1)\n",
    "    else: t1.append(0)    \n",
    "\n",
    "        \n",
    "for item in test_labels:\n",
    "    if str(item) == 'fraud': t2.append(1)\n",
    "    else: t2.append(0)        \n",
    "    \n",
    "train_y = np.array(t1)\n",
    "test_y = np.array(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DAtA LABEL VECTOR\n",
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING DAtA LABEL VECTOR\")\n",
    "print(train_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__() #DEFAULT CONSTRUCTOR INIT\n",
    "    \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') #USE BERT BASE FOR LIGHTER LOAD\n",
    "        self.dropout = nn.Dropout(dropout) #DROPOUT = DEFAULT\n",
    "        self.linear = nn.Linear(768, 1)    #LINEAR ACTIVATION LAYER, HIDDEN VECTOR LENGTH 768\n",
    "        self.sigmoid = nn.Sigmoid()        #SIGMOID ACTIVATION LAYER, S SHAPE DECISION BOUNDARY\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba\n",
    "    #FUNCTION ABOVE DEFINES FLOW OF DATA FOR BERT MODEL.\n",
    "    #POOLED OUTPUT = DEFAULT BERT POOLED OUTPUT, ABSTRACTION OF DATAPOINT\n",
    "    #DROPOUT = DEFAULT BERT DROPOUT\n",
    "    #LINEAR_OUTPUT = LINEAR ACTIVATION WITH HIDDEN SIZE 768\n",
    "    #FINAL STEP, PUT RESULT INTO SIGMOID ACTIVATION FOR RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)\n",
    "\n",
    "#CREATE TENSORS FOR TRAINING. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=1)\n",
    "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATEMENT BELOW ITERATES THROUGH EACH ITEM IN THE TRAINING DATASET AT ONE EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/1500.0 loss: 0.9540891051292419 \n",
      "Epoch:  1\n",
      "1/1500.0 loss: 0.8552638292312622 \n",
      "Epoch:  1\n",
      "2/1500.0 loss: 0.7748486200968424 \n",
      "Epoch:  1\n",
      "3/1500.0 loss: 0.7470849603414536 \n",
      "Epoch:  1\n",
      "4/1500.0 loss: 0.7315035462379456 \n",
      "Epoch:  1\n",
      "5/1500.0 loss: 0.7136586904525757 \n",
      "Epoch:  1\n",
      "6/1500.0 loss: 0.7053364174706596 \n",
      "Epoch:  1\n",
      "7/1500.0 loss: 0.7382429763674736 \n",
      "Epoch:  1\n",
      "8/1500.0 loss: 0.7337209979693095 \n",
      "Epoch:  1\n",
      "9/1500.0 loss: 0.7417612433433532 \n",
      "Epoch:  1\n",
      "10/1500.0 loss: 0.7208727273074064 \n",
      "Epoch:  1\n",
      "11/1500.0 loss: 0.7124467889467875 \n",
      "Epoch:  1\n",
      "12/1500.0 loss: 0.716227439733652 \n",
      "Epoch:  1\n",
      "13/1500.0 loss: 0.709198317357472 \n",
      "Epoch:  1\n",
      "14/1500.0 loss: 0.6997496088345846 \n",
      "Epoch:  1\n",
      "15/1500.0 loss: 0.6916990131139755 \n",
      "Epoch:  1\n",
      "16/1500.0 loss: 0.6848906594164231 \n",
      "Epoch:  1\n",
      "17/1500.0 loss: 0.6864752802583907 \n",
      "Epoch:  1\n",
      "18/1500.0 loss: 0.6987401560733193 \n",
      "Epoch:  1\n",
      "19/1500.0 loss: 0.7082746654748917 \n",
      "Epoch:  1\n",
      "20/1500.0 loss: 0.6988675367264521 \n",
      "Epoch:  1\n",
      "21/1500.0 loss: 0.6919686631722883 \n",
      "Epoch:  1\n",
      "22/1500.0 loss: 0.6849878974582838 \n",
      "Epoch:  1\n",
      "23/1500.0 loss: 0.6740037947893143 \n",
      "Epoch:  1\n",
      "24/1500.0 loss: 0.680737874507904 \n",
      "Epoch:  1\n",
      "25/1500.0 loss: 0.6888379408763006 \n",
      "Epoch:  1\n",
      "26/1500.0 loss: 0.6780658883077127 \n",
      "Epoch:  1\n",
      "27/1500.0 loss: 0.6696262529918126 \n",
      "Epoch:  1\n",
      "28/1500.0 loss: 0.6727296463374434 \n",
      "Epoch:  1\n",
      "29/1500.0 loss: 0.6799091756343841 \n",
      "Epoch:  1\n",
      "30/1500.0 loss: 0.6808235222293485 \n",
      "Epoch:  1\n",
      "31/1500.0 loss: 0.6766484193503857 \n",
      "Epoch:  1\n",
      "32/1500.0 loss: 0.6742876641678087 \n",
      "Epoch:  1\n",
      "33/1500.0 loss: 0.671076674671734 \n",
      "Epoch:  1\n",
      "34/1500.0 loss: 0.6652380509035928 \n",
      "Epoch:  1\n",
      "35/1500.0 loss: 0.6576883726649814 \n",
      "Epoch:  1\n",
      "36/1500.0 loss: 0.6515274885538462 \n",
      "Epoch:  1\n",
      "37/1500.0 loss: 0.6442797160462329 \n",
      "Epoch:  1\n",
      "38/1500.0 loss: 0.6428024516655848 \n",
      "Epoch:  1\n",
      "39/1500.0 loss: 0.6394355081021785 \n",
      "Epoch:  1\n",
      "40/1500.0 loss: 0.6450200655111452 \n",
      "Epoch:  1\n",
      "41/1500.0 loss: 0.6400826807532992 \n",
      "Epoch:  1\n",
      "42/1500.0 loss: 0.6339594111886135 \n",
      "Epoch:  1\n",
      "43/1500.0 loss: 0.628212304955179 \n",
      "Epoch:  1\n",
      "44/1500.0 loss: 0.633939391374588 \n",
      "Epoch:  1\n",
      "45/1500.0 loss: 0.6276387332574181 \n",
      "Epoch:  1\n",
      "46/1500.0 loss: 0.6339894704362179 \n",
      "Epoch:  1\n",
      "47/1500.0 loss: 0.6289228002230326 \n",
      "Epoch:  1\n",
      "48/1500.0 loss: 0.6236107501448417 \n",
      "Epoch:  1\n",
      "49/1500.0 loss: 0.6280850774049759 \n",
      "Epoch:  1\n",
      "50/1500.0 loss: 0.6249953186979481 \n",
      "Epoch:  1\n",
      "51/1500.0 loss: 0.6209713140359292 \n",
      "Epoch:  1\n",
      "52/1500.0 loss: 0.6212158529263623 \n",
      "Epoch:  1\n",
      "53/1500.0 loss: 0.623372166245072 \n",
      "Epoch:  1\n",
      "54/1500.0 loss: 0.6248100464994257 \n",
      "Epoch:  1\n",
      "55/1500.0 loss: 0.6295682830469949 \n",
      "Epoch:  1\n",
      "56/1500.0 loss: 0.6237787813471075 \n",
      "Epoch:  1\n",
      "57/1500.0 loss: 0.6203917413949966 \n",
      "Epoch:  1\n",
      "58/1500.0 loss: 0.624926722150738 \n",
      "Epoch:  1\n",
      "59/1500.0 loss: 0.6233206714193026 \n",
      "Epoch:  1\n",
      "60/1500.0 loss: 0.6201687596860479 \n",
      "Epoch:  1\n",
      "61/1500.0 loss: 0.6223135412700714 \n",
      "Epoch:  1\n",
      "62/1500.0 loss: 0.6182750501329937 \n",
      "Epoch:  1\n",
      "63/1500.0 loss: 0.6191143281757832 \n",
      "Epoch:  1\n",
      "64/1500.0 loss: 0.6215818441831149 \n",
      "Epoch:  1\n",
      "65/1500.0 loss: 0.6200245510448109 \n",
      "Epoch:  1\n",
      "66/1500.0 loss: 0.6158485043404708 \n",
      "Epoch:  1\n",
      "67/1500.0 loss: 0.6170442766126465 \n",
      "Epoch:  1\n",
      "68/1500.0 loss: 0.6135415672392085 \n",
      "Epoch:  1\n",
      "69/1500.0 loss: 0.6104839303663798 \n",
      "Epoch:  1\n",
      "70/1500.0 loss: 0.6126637891144819 \n",
      "Epoch:  1\n",
      "71/1500.0 loss: 0.6128167646626631 \n",
      "Epoch:  1\n",
      "72/1500.0 loss: 0.6111741878398477 \n",
      "Epoch:  1\n",
      "73/1500.0 loss: 0.6094537526369095 \n",
      "Epoch:  1\n",
      "74/1500.0 loss: 0.6096517368157705 \n",
      "Epoch:  1\n",
      "75/1500.0 loss: 0.6062239777100714 \n",
      "Epoch:  1\n",
      "76/1500.0 loss: 0.605855457968526 \n",
      "Epoch:  1\n",
      "77/1500.0 loss: 0.6029945516433471 \n",
      "Epoch:  1\n",
      "78/1500.0 loss: 0.6010350483127788 \n",
      "Epoch:  1\n",
      "79/1500.0 loss: 0.6021668154746294 \n",
      "Epoch:  1\n",
      "80/1500.0 loss: 0.5991881809852742 \n",
      "Epoch:  1\n",
      "81/1500.0 loss: 0.5962182977577535 \n",
      "Epoch:  1\n",
      "82/1500.0 loss: 0.5966538223157446 \n",
      "Epoch:  1\n",
      "83/1500.0 loss: 0.5978540086320469 \n",
      "Epoch:  1\n",
      "84/1500.0 loss: 0.5953502532313851 \n",
      "Epoch:  1\n",
      "85/1500.0 loss: 0.5932848751544952 \n",
      "Epoch:  1\n",
      "86/1500.0 loss: 0.5909045893570473 \n",
      "Epoch:  1\n",
      "87/1500.0 loss: 0.5876115066083994 \n",
      "Epoch:  1\n",
      "88/1500.0 loss: 0.5912267150503866 \n",
      "Epoch:  1\n",
      "89/1500.0 loss: 0.5887932694620557 \n",
      "Epoch:  1\n",
      "90/1500.0 loss: 0.5925624380399893 \n",
      "Epoch:  1\n",
      "91/1500.0 loss: 0.591442421078682 \n",
      "Epoch:  1\n",
      "92/1500.0 loss: 0.5890255397365939 \n",
      "Epoch:  1\n",
      "93/1500.0 loss: 0.5856157550786404 \n",
      "Epoch:  1\n",
      "94/1500.0 loss: 0.5865754940007862 \n",
      "Epoch:  1\n",
      "95/1500.0 loss: 0.5868287909155091 \n",
      "Epoch:  1\n",
      "96/1500.0 loss: 0.5869330932799074 \n",
      "Epoch:  1\n",
      "97/1500.0 loss: 0.5843056321752315 \n",
      "Epoch:  1\n",
      "98/1500.0 loss: 0.5830808507673668 \n",
      "Epoch:  1\n",
      "99/1500.0 loss: 0.5800185933709144 \n",
      "Epoch:  1\n",
      "100/1500.0 loss: 0.5770748664837072 \n",
      "Epoch:  1\n",
      "101/1500.0 loss: 0.5766199137650284 \n",
      "Epoch:  1\n",
      "102/1500.0 loss: 0.5753413971188 \n",
      "Epoch:  1\n",
      "103/1500.0 loss: 0.572656340037401 \n",
      "Epoch:  1\n",
      "104/1500.0 loss: 0.5714604786464146 \n",
      "Epoch:  1\n",
      "105/1500.0 loss: 0.5703511038478816 \n",
      "Epoch:  1\n",
      "106/1500.0 loss: 0.5681876593104033 \n",
      "Epoch:  1\n",
      "107/1500.0 loss: 0.5708205526073774 \n",
      "Epoch:  1\n",
      "108/1500.0 loss: 0.5691697622111084 \n",
      "Epoch:  1\n",
      "109/1500.0 loss: 0.5672830126502297 \n",
      "Epoch:  1\n",
      "110/1500.0 loss: 0.5659388346715016 \n",
      "Epoch:  1\n",
      "111/1500.0 loss: 0.5653205396873611 \n",
      "Epoch:  1\n",
      "112/1500.0 loss: 0.564023203818144 \n",
      "Epoch:  1\n",
      "113/1500.0 loss: 0.5622338304917017 \n",
      "Epoch:  1\n",
      "114/1500.0 loss: 0.5591592041046723 \n",
      "Epoch:  1\n",
      "115/1500.0 loss: 0.5566038752681223 \n",
      "Epoch:  1\n",
      "116/1500.0 loss: 0.5547832491306158 \n",
      "Epoch:  1\n",
      "117/1500.0 loss: 0.5525670348335121 \n",
      "Epoch:  1\n",
      "118/1500.0 loss: 0.5511299761153069 \n",
      "Epoch:  1\n",
      "119/1500.0 loss: 0.5489317905157804 \n",
      "Epoch:  1\n",
      "120/1500.0 loss: 0.5512277746249822 \n",
      "Epoch:  1\n",
      "121/1500.0 loss: 0.5491385959455224 \n",
      "Epoch:  1\n",
      "122/1500.0 loss: 0.5481780863147441 \n",
      "Epoch:  1\n",
      "123/1500.0 loss: 0.5486471070156943 \n",
      "Epoch:  1\n",
      "124/1500.0 loss: 0.5468921424150467 \n",
      "Epoch:  1\n",
      "125/1500.0 loss: 0.5440222927265697 \n",
      "Epoch:  1\n",
      "126/1500.0 loss: 0.5415501079456074 \n",
      "Epoch:  1\n",
      "127/1500.0 loss: 0.5397965527372435 \n",
      "Epoch:  1\n",
      "128/1500.0 loss: 0.5379762521316839 \n",
      "Epoch:  1\n",
      "129/1500.0 loss: 0.5365003644273831 \n",
      "Epoch:  1\n",
      "130/1500.0 loss: 0.5350990810694586 \n",
      "Epoch:  1\n",
      "131/1500.0 loss: 0.534324649721384 \n",
      "Epoch:  1\n",
      "132/1500.0 loss: 0.5323594796254223 \n",
      "Epoch:  1\n",
      "133/1500.0 loss: 0.5314130615164985 \n",
      "Epoch:  1\n",
      "134/1500.0 loss: 0.5299608752683357 \n",
      "Epoch:  1\n",
      "135/1500.0 loss: 0.5276935542111888 \n",
      "Epoch:  1\n",
      "136/1500.0 loss: 0.5262923992245737 \n",
      "Epoch:  1\n",
      "137/1500.0 loss: 0.52419997524956 \n",
      "Epoch:  1\n",
      "138/1500.0 loss: 0.5220506737986914 \n",
      "Epoch:  1\n",
      "139/1500.0 loss: 0.5200958534010819 \n",
      "Epoch:  1\n",
      "140/1500.0 loss: 0.5187871934885674 \n",
      "Epoch:  1\n",
      "141/1500.0 loss: 0.5190098282526916 \n",
      "Epoch:  1\n",
      "142/1500.0 loss: 0.5170393642428872 \n",
      "Epoch:  1\n",
      "143/1500.0 loss: 0.5160501971840858 \n",
      "Epoch:  1\n",
      "144/1500.0 loss: 0.5144627862963184 \n",
      "Epoch:  1\n",
      "145/1500.0 loss: 0.5126772410657308 \n",
      "Epoch:  1\n",
      "146/1500.0 loss: 0.5110733703691133 \n",
      "Epoch:  1\n",
      "147/1500.0 loss: 0.5094857308510188 \n",
      "Epoch:  1\n",
      "148/1500.0 loss: 0.5077399010426246 \n",
      "Epoch:  1\n",
      "149/1500.0 loss: 0.50754231462876 \n",
      "Epoch:  1\n",
      "150/1500.0 loss: 0.5058349235760455 \n",
      "Epoch:  1\n",
      "151/1500.0 loss: 0.50484607947108 \n",
      "Epoch:  1\n",
      "152/1500.0 loss: 0.5041136473806855 \n",
      "Epoch:  1\n",
      "153/1500.0 loss: 0.5024681608978804 \n",
      "Epoch:  1\n",
      "154/1500.0 loss: 0.5005563119726796 \n",
      "Epoch:  1\n",
      "155/1500.0 loss: 0.501856982612457 \n",
      "Epoch:  1\n",
      "156/1500.0 loss: 0.5012184801944501 \n",
      "Epoch:  1\n",
      "157/1500.0 loss: 0.5006890822249123 \n",
      "Epoch:  1\n",
      "158/1500.0 loss: 0.49926222804582343 \n",
      "Epoch:  1\n",
      "159/1500.0 loss: 0.49774020751938225 \n",
      "Epoch:  1\n",
      "160/1500.0 loss: 0.49643787343679746 \n",
      "Epoch:  1\n",
      "161/1500.0 loss: 0.4945159846065957 \n",
      "Epoch:  1\n",
      "162/1500.0 loss: 0.49264659014947576 \n",
      "Epoch:  1\n",
      "163/1500.0 loss: 0.4908182484711089 \n",
      "Epoch:  1\n",
      "164/1500.0 loss: 0.49146863420804343 \n",
      "Epoch:  1\n",
      "165/1500.0 loss: 0.49039296213402805 \n",
      "Epoch:  1\n",
      "166/1500.0 loss: 0.4887376148365215 \n",
      "Epoch:  1\n",
      "167/1500.0 loss: 0.4869439156637305 \n",
      "Epoch:  1\n",
      "168/1500.0 loss: 0.4854346714781586 \n",
      "Epoch:  1\n",
      "169/1500.0 loss: 0.4839612824075362 \n",
      "Epoch:  1\n",
      "170/1500.0 loss: 0.48268145270514906 \n",
      "Epoch:  1\n",
      "171/1500.0 loss: 0.4812255843954031 \n",
      "Epoch:  1\n",
      "172/1500.0 loss: 0.48329196904780547 \n",
      "Epoch:  1\n",
      "173/1500.0 loss: 0.4817713365472596 \n",
      "Epoch:  1\n",
      "174/1500.0 loss: 0.4807381415367126 \n",
      "Epoch:  1\n",
      "175/1500.0 loss: 0.4792803434485739 \n",
      "Epoch:  1\n",
      "176/1500.0 loss: 0.4780684345859592 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "177/1500.0 loss: 0.4774705275390925 \n",
      "Epoch:  1\n",
      "178/1500.0 loss: 0.4759362056934634 \n",
      "Epoch:  1\n",
      "179/1500.0 loss: 0.4747659570640988 \n",
      "Epoch:  1\n",
      "180/1500.0 loss: 0.473611689074922 \n",
      "Epoch:  1\n",
      "181/1500.0 loss: 0.47248832963325166 \n",
      "Epoch:  1\n",
      "182/1500.0 loss: 0.4712655394455123 \n",
      "Epoch:  1\n",
      "183/1500.0 loss: 0.4701238465697869 \n",
      "Epoch:  1\n",
      "184/1500.0 loss: 0.46895878830471555 \n",
      "Epoch:  1\n",
      "185/1500.0 loss: 0.46912934318665533 \n",
      "Epoch:  1\n",
      "186/1500.0 loss: 0.4682016712140272 \n",
      "Epoch:  1\n",
      "187/1500.0 loss: 0.4668822331314391 \n",
      "Epoch:  1\n",
      "188/1500.0 loss: 0.4653381373358782 \n",
      "Epoch:  1\n",
      "189/1500.0 loss: 0.46389280612531464 \n",
      "Epoch:  1\n",
      "190/1500.0 loss: 0.46402242818740025 \n",
      "Epoch:  1\n",
      "191/1500.0 loss: 0.4625569907948375 \n",
      "Epoch:  1\n",
      "192/1500.0 loss: 0.46124245681910936 \n",
      "Epoch:  1\n",
      "193/1500.0 loss: 0.4604291263007626 \n",
      "Epoch:  1\n",
      "194/1500.0 loss: 0.45906574588555554 \n",
      "Epoch:  1\n",
      "195/1500.0 loss: 0.45766037702560425 \n",
      "Epoch:  1\n",
      "196/1500.0 loss: 0.4566093746780744 \n",
      "Epoch:  1\n",
      "197/1500.0 loss: 0.4552609755685835 \n",
      "Epoch:  1\n",
      "198/1500.0 loss: 0.4541518467305294 \n",
      "Epoch:  1\n",
      "199/1500.0 loss: 0.4529534835368395 \n",
      "Epoch:  1\n",
      "200/1500.0 loss: 0.4523066747099606 \n",
      "Epoch:  1\n",
      "201/1500.0 loss: 0.45111802021170605 \n",
      "Epoch:  1\n",
      "202/1500.0 loss: 0.4499512010166798 \n",
      "Epoch:  1\n",
      "203/1500.0 loss: 0.44877002994511644 \n",
      "Epoch:  1\n",
      "204/1500.0 loss: 0.4474836355302392 \n",
      "Epoch:  1\n",
      "205/1500.0 loss: 0.4465210817537261 \n",
      "Epoch:  1\n",
      "206/1500.0 loss: 0.4458187275030763 \n",
      "Epoch:  1\n",
      "207/1500.0 loss: 0.44454369242661274 \n",
      "Epoch:  1\n",
      "208/1500.0 loss: 0.4435118682076486 \n",
      "Epoch:  1\n",
      "209/1500.0 loss: 0.44243257911432354 \n",
      "Epoch:  1\n",
      "210/1500.0 loss: 0.4410941105035809 \n",
      "Epoch:  1\n",
      "211/1500.0 loss: 0.44006076216135387 \n",
      "Epoch:  1\n",
      "212/1500.0 loss: 0.43917522519966806 \n",
      "Epoch:  1\n",
      "213/1500.0 loss: 0.4378730725044402 \n",
      "Epoch:  1\n",
      "214/1500.0 loss: 0.4368001487365989 \n",
      "Epoch:  1\n",
      "215/1500.0 loss: 0.43572723734434005 \n",
      "Epoch:  1\n",
      "216/1500.0 loss: 0.43508700875367984 \n",
      "Epoch:  1\n",
      "217/1500.0 loss: 0.4338154417522457 \n",
      "Epoch:  1\n",
      "218/1500.0 loss: 0.4326469574344757 \n",
      "Epoch:  1\n",
      "219/1500.0 loss: 0.4317075100812045 \n",
      "Epoch:  1\n",
      "220/1500.0 loss: 0.4305366449631177 \n",
      "Epoch:  1\n",
      "221/1500.0 loss: 0.4301357374669195 \n",
      "Epoch:  1\n",
      "222/1500.0 loss: 0.4292427707680672 \n",
      "Epoch:  1\n",
      "223/1500.0 loss: 0.4281006572502 \n",
      "Epoch:  1\n",
      "224/1500.0 loss: 0.4270057681534025 \n",
      "Epoch:  1\n",
      "225/1500.0 loss: 0.42583918011030264 \n",
      "Epoch:  1\n",
      "226/1500.0 loss: 0.42479336668741335 \n",
      "Epoch:  1\n",
      "227/1500.0 loss: 0.42373839334437724 \n",
      "Epoch:  1\n",
      "228/1500.0 loss: 0.425201183062974 \n",
      "Epoch:  1\n",
      "229/1500.0 loss: 0.42434534372194954 \n",
      "Epoch:  1\n",
      "230/1500.0 loss: 0.42328455050786334 \n",
      "Epoch:  1\n",
      "231/1500.0 loss: 0.4222501742428747 \n",
      "Epoch:  1\n",
      "232/1500.0 loss: 0.4211926986603266 \n",
      "Epoch:  1\n",
      "233/1500.0 loss: 0.4201040044426918 \n",
      "Epoch:  1\n",
      "234/1500.0 loss: 0.418792669284851 \n",
      "Epoch:  1\n",
      "235/1500.0 loss: 0.4177369652473826 \n",
      "Epoch:  1\n",
      "236/1500.0 loss: 0.4167327732790875 \n",
      "Epoch:  1\n",
      "237/1500.0 loss: 0.4155311318067442 \n",
      "Epoch:  1\n",
      "238/1500.0 loss: 0.41443971002076957 \n",
      "Epoch:  1\n",
      "239/1500.0 loss: 0.4134815468452871 \n",
      "Epoch:  1\n",
      "240/1500.0 loss: 0.412419770299399 \n",
      "Epoch:  1\n",
      "241/1500.0 loss: 0.41429669308391487 \n",
      "Epoch:  1\n",
      "242/1500.0 loss: 0.4132707367647332 \n",
      "Epoch:  1\n",
      "243/1500.0 loss: 0.4124381527243579 \n",
      "Epoch:  1\n",
      "244/1500.0 loss: 0.4114973389676639 \n",
      "Epoch:  1\n",
      "245/1500.0 loss: 0.4104818969177521 \n",
      "Epoch:  1\n",
      "246/1500.0 loss: 0.40948764464029896 \n",
      "Epoch:  1\n",
      "247/1500.0 loss: 0.40891148255116516 \n",
      "Epoch:  1\n",
      "248/1500.0 loss: 0.4078734200821823 \n",
      "Epoch:  1\n",
      "249/1500.0 loss: 0.4070794188082218 \n",
      "Epoch:  1\n",
      "250/1500.0 loss: 0.40628209166911494 \n",
      "Epoch:  1\n",
      "251/1500.0 loss: 0.4056743034826858 \n",
      "Epoch:  1\n",
      "252/1500.0 loss: 0.4055659415516929 \n",
      "Epoch:  1\n",
      "253/1500.0 loss: 0.40473887409398873 \n",
      "Epoch:  1\n",
      "254/1500.0 loss: 0.4036936923861504 \n",
      "Epoch:  1\n",
      "255/1500.0 loss: 0.4031248187238816 \n",
      "Epoch:  1\n",
      "256/1500.0 loss: 0.4019733075385892 \n",
      "Epoch:  1\n",
      "257/1500.0 loss: 0.40132104946199315 \n",
      "Epoch:  1\n",
      "258/1500.0 loss: 0.40033295940478336 \n",
      "Epoch:  1\n",
      "259/1500.0 loss: 0.3996947234066633 \n",
      "Epoch:  1\n",
      "260/1500.0 loss: 0.3987663579512373 \n",
      "Epoch:  1\n",
      "261/1500.0 loss: 0.39773695711188645 \n",
      "Epoch:  1\n",
      "262/1500.0 loss: 0.39681562186420644 \n",
      "Epoch:  1\n",
      "263/1500.0 loss: 0.396077615970915 \n",
      "Epoch:  1\n",
      "264/1500.0 loss: 0.39513276523014285 \n",
      "Epoch:  1\n",
      "265/1500.0 loss: 0.39413972949623166 \n",
      "Epoch:  1\n",
      "266/1500.0 loss: 0.393502478184325 \n",
      "Epoch:  1\n",
      "267/1500.0 loss: 0.39271090374286494 \n",
      "Epoch:  1\n",
      "268/1500.0 loss: 0.39193502694479154 \n",
      "Epoch:  1\n",
      "269/1500.0 loss: 0.3921487999735055 \n",
      "Epoch:  1\n",
      "270/1500.0 loss: 0.39137234112653346 \n",
      "Epoch:  1\n",
      "271/1500.0 loss: 0.3911756244761979 \n",
      "Epoch:  1\n",
      "272/1500.0 loss: 0.3902079008874439 \n",
      "Epoch:  1\n",
      "273/1500.0 loss: 0.38956428536750975 \n",
      "Epoch:  1\n",
      "274/1500.0 loss: 0.38862335790287367 \n",
      "Epoch:  1\n",
      "275/1500.0 loss: 0.3879420213617276 \n",
      "Epoch:  1\n",
      "276/1500.0 loss: 0.38709540740462417 \n",
      "Epoch:  1\n",
      "277/1500.0 loss: 0.38618949538083386 \n",
      "Epoch:  1\n",
      "278/1500.0 loss: 0.3856259432744809 \n",
      "Epoch:  1\n",
      "279/1500.0 loss: 0.38478360144155366 \n",
      "Epoch:  1\n",
      "280/1500.0 loss: 0.3841414819090392 \n",
      "Epoch:  1\n",
      "281/1500.0 loss: 0.38320463285484213 \n",
      "Epoch:  1\n",
      "282/1500.0 loss: 0.3825755899396886 \n",
      "Epoch:  1\n",
      "283/1500.0 loss: 0.38230322015432405 \n",
      "Epoch:  1\n",
      "284/1500.0 loss: 0.3813313899071593 \n",
      "Epoch:  1\n",
      "285/1500.0 loss: 0.3805384325658108 \n",
      "Epoch:  1\n",
      "286/1500.0 loss: 0.3796627361859594 \n",
      "Epoch:  1\n",
      "287/1500.0 loss: 0.378820304112095 \n",
      "Epoch:  1\n",
      "288/1500.0 loss: 0.37795159419205776 \n",
      "Epoch:  1\n",
      "289/1500.0 loss: 0.3773366916025507 \n",
      "Epoch:  1\n",
      "290/1500.0 loss: 0.37632178658574716 \n",
      "Epoch:  1\n",
      "291/1500.0 loss: 0.3772527139940082 \n",
      "Epoch:  1\n",
      "292/1500.0 loss: 0.37662339146938745 \n",
      "Epoch:  1\n",
      "293/1500.0 loss: 0.37573645547741935 \n",
      "Epoch:  1\n",
      "294/1500.0 loss: 0.3748879610987033 \n",
      "Epoch:  1\n",
      "295/1500.0 loss: 0.37402206430262 \n",
      "Epoch:  1\n",
      "296/1500.0 loss: 0.3734590639720862 \n",
      "Epoch:  1\n",
      "297/1500.0 loss: 0.3725376881208996 \n",
      "Epoch:  1\n",
      "298/1500.0 loss: 0.3716266219781394 \n",
      "Epoch:  1\n",
      "299/1500.0 loss: 0.3708528479188681 \n",
      "Epoch:  1\n",
      "300/1500.0 loss: 0.3701180735745303 \n",
      "Epoch:  1\n",
      "301/1500.0 loss: 0.36926501231971165 \n",
      "Epoch:  1\n",
      "302/1500.0 loss: 0.3684625394716121 \n",
      "Epoch:  1\n",
      "303/1500.0 loss: 0.3678035107931416 \n",
      "Epoch:  1\n",
      "304/1500.0 loss: 0.36715514354529927 \n",
      "Epoch:  1\n",
      "305/1500.0 loss: 0.3663660065557053 \n",
      "Epoch:  1\n",
      "306/1500.0 loss: 0.36583501311680394 \n",
      "Epoch:  1\n",
      "307/1500.0 loss: 0.3649965414608067 \n",
      "Epoch:  1\n",
      "308/1500.0 loss: 0.3642942372311666 \n",
      "Epoch:  1\n",
      "309/1500.0 loss: 0.3633900530155628 \n",
      "Epoch:  1\n",
      "310/1500.0 loss: 0.36267880053286383 \n",
      "Epoch:  1\n",
      "311/1500.0 loss: 0.3618822957938298 \n",
      "Epoch:  1\n",
      "312/1500.0 loss: 0.3610873194262623 \n",
      "Epoch:  1\n",
      "313/1500.0 loss: 0.36040398891374564 \n",
      "Epoch:  1\n",
      "314/1500.0 loss: 0.359650766187244 \n",
      "Epoch:  1\n",
      "315/1500.0 loss: 0.35879651296742354 \n",
      "Epoch:  1\n",
      "316/1500.0 loss: 0.35820995087879315 \n",
      "Epoch:  1\n",
      "317/1500.0 loss: 0.35742412439588483 \n",
      "Epoch:  1\n",
      "318/1500.0 loss: 0.361215425299066 \n",
      "Epoch:  1\n",
      "319/1500.0 loss: 0.36652171665336936 \n",
      "Epoch:  1\n",
      "320/1500.0 loss: 0.3656718173641653 \n",
      "Epoch:  1\n",
      "321/1500.0 loss: 0.3648288987623238 \n",
      "Epoch:  1\n",
      "322/1500.0 loss: 0.36410544199102063 \n",
      "Epoch:  1\n",
      "323/1500.0 loss: 0.36333166902171976 \n",
      "Epoch:  1\n",
      "324/1500.0 loss: 0.3625100152079876 \n",
      "Epoch:  1\n",
      "325/1500.0 loss: 0.36178083854950277 \n",
      "Epoch:  1\n",
      "326/1500.0 loss: 0.36097437710663594 \n",
      "Epoch:  1\n",
      "327/1500.0 loss: 0.3611966649797268 \n",
      "Epoch:  1\n",
      "328/1500.0 loss: 0.36073699962676115 \n",
      "Epoch:  1\n",
      "329/1500.0 loss: 0.3603390581002741 \n",
      "Epoch:  1\n",
      "330/1500.0 loss: 0.3597962434693406 \n",
      "Epoch:  1\n",
      "331/1500.0 loss: 0.35901287732174597 \n",
      "Epoch:  1\n",
      "332/1500.0 loss: 0.35828449905992626 \n",
      "Epoch:  1\n",
      "333/1500.0 loss: 0.3581951902565842 \n",
      "Epoch:  1\n",
      "334/1500.0 loss: 0.35767390941506 \n",
      "Epoch:  1\n",
      "335/1500.0 loss: 0.3568653107975565 \n",
      "Epoch:  1\n",
      "336/1500.0 loss: 0.3560546889503207 \n",
      "Epoch:  1\n",
      "337/1500.0 loss: 0.355519209431826 \n",
      "Epoch:  1\n",
      "338/1500.0 loss: 0.35477942916232225 \n",
      "Epoch:  1\n",
      "339/1500.0 loss: 0.35397949071929735 \n",
      "Epoch:  1\n",
      "340/1500.0 loss: 0.3535684369220412 \n",
      "Epoch:  1\n",
      "341/1500.0 loss: 0.3533271763974812 \n",
      "Epoch:  1\n",
      "342/1500.0 loss: 0.3525957558141158 \n",
      "Epoch:  1\n",
      "343/1500.0 loss: 0.3523367986429569 \n",
      "Epoch:  1\n",
      "344/1500.0 loss: 0.3515709972899893 \n",
      "Epoch:  1\n",
      "345/1500.0 loss: 0.3508248206421819 \n",
      "Epoch:  1\n",
      "346/1500.0 loss: 0.35007574087175236 \n",
      "Epoch:  1\n",
      "347/1500.0 loss: 0.34935589734165146 \n",
      "Epoch:  1\n",
      "348/1500.0 loss: 0.34875776911191747 \n",
      "Epoch:  1\n",
      "349/1500.0 loss: 0.3480299867902483 \n",
      "Epoch:  1\n",
      "350/1500.0 loss: 0.3516415941749203 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "351/1500.0 loss: 0.3510370060208846 \n",
      "Epoch:  1\n",
      "352/1500.0 loss: 0.35585279864055913 \n",
      "Epoch:  1\n",
      "353/1500.0 loss: 0.35562756047242106 \n",
      "Epoch:  1\n",
      "354/1500.0 loss: 0.3549819291477472 \n",
      "Epoch:  1\n",
      "355/1500.0 loss: 0.3542881270640352 \n",
      "Epoch:  1\n",
      "356/1500.0 loss: 0.35384802607929006 \n",
      "Epoch:  1\n",
      "357/1500.0 loss: 0.35326113414498017 \n",
      "Epoch:  1\n",
      "358/1500.0 loss: 0.3525186390680855 \n",
      "Epoch:  1\n",
      "359/1500.0 loss: 0.351958088328441 \n",
      "Epoch:  1\n",
      "360/1500.0 loss: 0.3512811766436886 \n",
      "Epoch:  1\n",
      "361/1500.0 loss: 0.3531514297532772 \n",
      "Epoch:  1\n",
      "362/1500.0 loss: 0.3524560807862886 \n",
      "Epoch:  1\n",
      "363/1500.0 loss: 0.35195703143356266 \n",
      "Epoch:  1\n",
      "364/1500.0 loss: 0.3513706901097951 \n",
      "Epoch:  1\n",
      "365/1500.0 loss: 0.3506962750005266 \n",
      "Epoch:  1\n",
      "366/1500.0 loss: 0.3501877541316303 \n",
      "Epoch:  1\n",
      "367/1500.0 loss: 0.3494911390437704 \n",
      "Epoch:  1\n",
      "368/1500.0 loss: 0.34887309382520715 \n",
      "Epoch:  1\n",
      "369/1500.0 loss: 0.3482145209972923 \n",
      "Epoch:  1\n",
      "370/1500.0 loss: 0.3476005029887202 \n",
      "Epoch:  1\n",
      "371/1500.0 loss: 0.3469040060556063 \n",
      "Epoch:  1\n",
      "372/1500.0 loss: 0.34627208736882453 \n",
      "Epoch:  1\n",
      "373/1500.0 loss: 0.34566484409618503 \n",
      "Epoch:  1\n",
      "374/1500.0 loss: 0.3451186540722847 \n",
      "Epoch:  1\n",
      "375/1500.0 loss: 0.3444573503146146 \n",
      "Epoch:  1\n",
      "376/1500.0 loss: 0.3439246812929209 \n",
      "Epoch:  1\n",
      "377/1500.0 loss: 0.34329108229626426 \n",
      "Epoch:  1\n",
      "378/1500.0 loss: 0.34294877327133294 \n",
      "Epoch:  1\n",
      "379/1500.0 loss: 0.34238510286729584 \n",
      "Epoch:  1\n",
      "380/1500.0 loss: 0.3417799786671879 \n",
      "Epoch:  1\n",
      "381/1500.0 loss: 0.34118365568562325 \n",
      "Epoch:  1\n",
      "382/1500.0 loss: 0.3434698688882761 \n",
      "Epoch:  1\n",
      "383/1500.0 loss: 0.3428584089075836 \n",
      "Epoch:  1\n",
      "384/1500.0 loss: 0.34225680431375255 \n",
      "Epoch:  1\n",
      "385/1500.0 loss: 0.3416274555336317 \n",
      "Epoch:  1\n",
      "386/1500.0 loss: 0.34104512389316116 \n",
      "Epoch:  1\n",
      "387/1500.0 loss: 0.34040577859454546 \n",
      "Epoch:  1\n",
      "388/1500.0 loss: 0.3397933141086586 \n",
      "Epoch:  1\n",
      "389/1500.0 loss: 0.3391925366070026 \n",
      "Epoch:  1\n",
      "390/1500.0 loss: 0.3385547897242524 \n",
      "Epoch:  1\n",
      "391/1500.0 loss: 0.33792569674551487 \n",
      "Epoch:  1\n",
      "392/1500.0 loss: 0.3372861199630732 \n",
      "Epoch:  1\n",
      "393/1500.0 loss: 0.33665387270036085 \n",
      "Epoch:  1\n",
      "394/1500.0 loss: 0.3359954465416413 \n",
      "Epoch:  1\n",
      "395/1500.0 loss: 0.3355292903654503 \n",
      "Epoch:  1\n",
      "396/1500.0 loss: 0.3350781717288404 \n",
      "Epoch:  1\n",
      "397/1500.0 loss: 0.33465786944681675 \n",
      "Epoch:  1\n",
      "398/1500.0 loss: 0.33418527219379157 \n",
      "Epoch:  1\n",
      "399/1500.0 loss: 0.33367425341159107 \n",
      "Epoch:  1\n",
      "400/1500.0 loss: 0.33303797789419676 \n",
      "Epoch:  1\n",
      "401/1500.0 loss: 0.3324297408744767 \n",
      "Epoch:  1\n",
      "402/1500.0 loss: 0.33197888334468934 \n",
      "Epoch:  1\n",
      "403/1500.0 loss: 0.33139899398873346 \n",
      "Epoch:  1\n",
      "404/1500.0 loss: 0.33093826910595836 \n",
      "Epoch:  1\n",
      "405/1500.0 loss: 0.33069448962147013 \n",
      "Epoch:  1\n",
      "406/1500.0 loss: 0.3300533338795423 \n",
      "Epoch:  1\n",
      "407/1500.0 loss: 0.3294455201237225 \n",
      "Epoch:  1\n",
      "408/1500.0 loss: 0.3291579606261988 \n",
      "Epoch:  1\n",
      "409/1500.0 loss: 0.32868412718540285 \n",
      "Epoch:  1\n",
      "410/1500.0 loss: 0.3281305641697271 \n",
      "Epoch:  1\n",
      "411/1500.0 loss: 0.3276001730734862 \n",
      "Epoch:  1\n",
      "412/1500.0 loss: 0.3271425819570158 \n",
      "Epoch:  1\n",
      "413/1500.0 loss: 0.3265343801914782 \n",
      "Epoch:  1\n",
      "414/1500.0 loss: 0.32605498271534245 \n",
      "Epoch:  1\n",
      "415/1500.0 loss: 0.3254798125439825 \n",
      "Epoch:  1\n",
      "416/1500.0 loss: 0.3250347376405764 \n",
      "Epoch:  1\n",
      "417/1500.0 loss: 0.32462676284772357 \n",
      "Epoch:  1\n",
      "418/1500.0 loss: 0.3240481415732379 \n",
      "Epoch:  1\n",
      "419/1500.0 loss: 0.3236314245455322 \n",
      "Epoch:  1\n",
      "420/1500.0 loss: 0.32311708265981876 \n",
      "Epoch:  1\n",
      "421/1500.0 loss: 0.3225338916996079 \n",
      "Epoch:  1\n",
      "422/1500.0 loss: 0.3222969026782552 \n",
      "Epoch:  1\n",
      "423/1500.0 loss: 0.32181322660718886 \n",
      "Epoch:  1\n",
      "424/1500.0 loss: 0.3213338757613126 \n",
      "Epoch:  1\n",
      "425/1500.0 loss: 0.32106990052360884 \n",
      "Epoch:  1\n",
      "426/1500.0 loss: 0.32058665617009235 \n",
      "Epoch:  1\n",
      "427/1500.0 loss: 0.31999057715880536 \n",
      "Epoch:  1\n",
      "428/1500.0 loss: 0.3194806881961011 \n",
      "Epoch:  1\n",
      "429/1500.0 loss: 0.3190497163250003 \n",
      "Epoch:  1\n",
      "430/1500.0 loss: 0.3185209745320809 \n",
      "Epoch:  1\n",
      "431/1500.0 loss: 0.31793806750189374 \n",
      "Epoch:  1\n",
      "432/1500.0 loss: 0.31737098655304236 \n",
      "Epoch:  1\n",
      "433/1500.0 loss: 0.3168083412856001 \n",
      "Epoch:  1\n",
      "434/1500.0 loss: 0.3163583176060655 \n",
      "Epoch:  1\n",
      "435/1500.0 loss: 0.316018781821252 \n",
      "Epoch:  1\n",
      "436/1500.0 loss: 0.31546425156175956 \n",
      "Epoch:  1\n",
      "437/1500.0 loss: 0.31506378443477906 \n",
      "Epoch:  1\n",
      "438/1500.0 loss: 0.31453905000026783 \n",
      "Epoch:  1\n",
      "439/1500.0 loss: 0.3139781863513318 \n",
      "Epoch:  1\n",
      "440/1500.0 loss: 0.31340546872204933 \n",
      "Epoch:  1\n",
      "441/1500.0 loss: 0.3165335453945587 \n",
      "Epoch:  1\n",
      "442/1500.0 loss: 0.316214662642296 \n",
      "Epoch:  1\n",
      "443/1500.0 loss: 0.31572394130063486 \n",
      "Epoch:  1\n",
      "444/1500.0 loss: 0.3151669802792956 \n",
      "Epoch:  1\n",
      "445/1500.0 loss: 0.31465157250051007 \n",
      "Epoch:  1\n",
      "446/1500.0 loss: 0.3142689988017082 \n",
      "Epoch:  1\n",
      "447/1500.0 loss: 0.31371507490985096 \n",
      "Epoch:  1\n",
      "448/1500.0 loss: 0.31315569737241633 \n",
      "Epoch:  1\n",
      "449/1500.0 loss: 0.3128070004284382 \n",
      "Epoch:  1\n",
      "450/1500.0 loss: 0.31247173552039986 \n",
      "Epoch:  1\n",
      "451/1500.0 loss: 0.3121937121866287 \n",
      "Epoch:  1\n",
      "452/1500.0 loss: 0.31211283186216227 \n",
      "Epoch:  1\n",
      "453/1500.0 loss: 0.31156791034380243 \n",
      "Epoch:  1\n",
      "454/1500.0 loss: 0.3111279098542182 \n",
      "Epoch:  1\n",
      "455/1500.0 loss: 0.3106933072405426 \n",
      "Epoch:  1\n",
      "456/1500.0 loss: 0.31013010314276496 \n",
      "Epoch:  1\n",
      "457/1500.0 loss: 0.30970799294198703 \n",
      "Epoch:  1\n",
      "458/1500.0 loss: 0.3093941661575911 \n",
      "Epoch:  1\n",
      "459/1500.0 loss: 0.30886675431190624 \n",
      "Epoch:  1\n",
      "460/1500.0 loss: 0.3083765299631174 \n",
      "Epoch:  1\n",
      "461/1500.0 loss: 0.30783927039086045 \n",
      "Epoch:  1\n",
      "462/1500.0 loss: 0.30749562191203655 \n",
      "Epoch:  1\n",
      "463/1500.0 loss: 0.3071672125912175 \n",
      "Epoch:  1\n",
      "464/1500.0 loss: 0.30667464111440923 \n",
      "Epoch:  1\n",
      "465/1500.0 loss: 0.3069951731887498 \n",
      "Epoch:  1\n",
      "466/1500.0 loss: 0.3064639685751284 \n",
      "Epoch:  1\n",
      "467/1500.0 loss: 0.30594182800915504 \n",
      "Epoch:  1\n",
      "468/1500.0 loss: 0.30551459591017605 \n",
      "Epoch:  1\n",
      "469/1500.0 loss: 0.30507581945746504 \n",
      "Epoch:  1\n",
      "470/1500.0 loss: 0.30637138134418274 \n",
      "Epoch:  1\n",
      "471/1500.0 loss: 0.3059165056447609 \n",
      "Epoch:  1\n",
      "472/1500.0 loss: 0.3053944231607571 \n",
      "Epoch:  1\n",
      "473/1500.0 loss: 0.30501797368537775 \n",
      "Epoch:  1\n",
      "474/1500.0 loss: 0.3045339120924473 \n",
      "Epoch:  1\n",
      "475/1500.0 loss: 0.30414307122940526 \n",
      "Epoch:  1\n",
      "476/1500.0 loss: 0.3036882638290868 \n",
      "Epoch:  1\n",
      "477/1500.0 loss: 0.3032594573874977 \n",
      "Epoch:  1\n",
      "478/1500.0 loss: 0.30278589266171535 \n",
      "Epoch:  1\n",
      "479/1500.0 loss: 0.302320063742809 \n",
      "Epoch:  1\n",
      "480/1500.0 loss: 0.30187671770208097 \n",
      "Epoch:  1\n",
      "481/1500.0 loss: 0.3015130598221701 \n",
      "Epoch:  1\n",
      "482/1500.0 loss: 0.30101659846170103 \n",
      "Epoch:  1\n",
      "483/1500.0 loss: 0.30075506642768696 \n",
      "Epoch:  1\n",
      "484/1500.0 loss: 0.30025645364651976 \n",
      "Epoch:  1\n",
      "485/1500.0 loss: 0.30000731875591075 \n",
      "Epoch:  1\n",
      "486/1500.0 loss: 0.29950826326710245 \n",
      "Epoch:  1\n",
      "487/1500.0 loss: 0.29902323882752024 \n",
      "Epoch:  1\n",
      "488/1500.0 loss: 0.29862405214237775 \n",
      "Epoch:  1\n",
      "489/1500.0 loss: 0.29813861794465657 \n",
      "Epoch:  1\n",
      "490/1500.0 loss: 0.297651343055206 \n",
      "Epoch:  1\n",
      "491/1500.0 loss: 0.29723411812863454 \n",
      "Epoch:  1\n",
      "492/1500.0 loss: 0.2968362028848448 \n",
      "Epoch:  1\n",
      "493/1500.0 loss: 0.29648549511636557 \n",
      "Epoch:  1\n",
      "494/1500.0 loss: 0.29602743725132463 \n",
      "Epoch:  1\n",
      "495/1500.0 loss: 0.2956672364530424 \n",
      "Epoch:  1\n",
      "496/1500.0 loss: 0.2953091249154727 \n",
      "Epoch:  1\n",
      "497/1500.0 loss: 0.2948513446098949 \n",
      "Epoch:  1\n",
      "498/1500.0 loss: 0.29441327875655493 \n",
      "Epoch:  1\n",
      "499/1500.0 loss: 0.2940071775391698 \n",
      "Epoch:  1\n",
      "500/1500.0 loss: 0.29366481759977675 \n",
      "Epoch:  1\n",
      "501/1500.0 loss: 0.2933357503205775 \n",
      "Epoch:  1\n",
      "502/1500.0 loss: 0.29296297324491777 \n",
      "Epoch:  1\n",
      "503/1500.0 loss: 0.29251955249272876 \n",
      "Epoch:  1\n",
      "504/1500.0 loss: 0.2920658800345246 \n",
      "Epoch:  1\n",
      "505/1500.0 loss: 0.291613717994141 \n",
      "Epoch:  1\n",
      "506/1500.0 loss: 0.2911991138062651 \n",
      "Epoch:  1\n",
      "507/1500.0 loss: 0.29081476672633194 \n",
      "Epoch:  1\n",
      "508/1500.0 loss: 0.2903598732880384 \n",
      "Epoch:  1\n",
      "509/1500.0 loss: 0.29001423956132405 \n",
      "Epoch:  1\n",
      "510/1500.0 loss: 0.2895466442677373 \n",
      "Epoch:  1\n",
      "511/1500.0 loss: 0.2891213891853113 \n",
      "Epoch:  1\n",
      "512/1500.0 loss: 0.2886582749803164 \n",
      "Epoch:  1\n",
      "513/1500.0 loss: 0.28822764161437864 \n",
      "Epoch:  1\n",
      "514/1500.0 loss: 0.2877658123964245 \n",
      "Epoch:  1\n",
      "515/1500.0 loss: 0.2872961844541421 \n",
      "Epoch:  1\n",
      "516/1500.0 loss: 0.2868235220257157 \n",
      "Epoch:  1\n",
      "517/1500.0 loss: 0.2864252422004938 \n",
      "Epoch:  1\n",
      "518/1500.0 loss: 0.2860819661706284 \n",
      "Epoch:  1\n",
      "519/1500.0 loss: 0.2856937166518317 \n",
      "Epoch:  1\n",
      "520/1500.0 loss: 0.28524267126496833 \n",
      "Epoch:  1\n",
      "521/1500.0 loss: 0.28486314002724217 \n",
      "Epoch:  1\n",
      "522/1500.0 loss: 0.28447711222001976 \n",
      "Epoch:  1\n",
      "523/1500.0 loss: 0.28414539019541657 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "524/1500.0 loss: 0.28378107463320096 \n",
      "Epoch:  1\n",
      "525/1500.0 loss: 0.28337908977423104 \n",
      "Epoch:  1\n",
      "526/1500.0 loss: 0.28306696878523485 \n",
      "Epoch:  1\n",
      "527/1500.0 loss: 0.28264464030860725 \n",
      "Epoch:  1\n",
      "528/1500.0 loss: 0.2823371685027287 \n",
      "Epoch:  1\n",
      "529/1500.0 loss: 0.2819658887203572 \n",
      "Epoch:  1\n",
      "530/1500.0 loss: 0.2815510601492813 \n",
      "Epoch:  1\n",
      "531/1500.0 loss: 0.2811479856491201 \n",
      "Epoch:  1\n",
      "532/1500.0 loss: 0.2808051092889139 \n",
      "Epoch:  1\n",
      "533/1500.0 loss: 0.2804129950576619 \n",
      "Epoch:  1\n",
      "534/1500.0 loss: 0.28010563502941177 \n",
      "Epoch:  1\n",
      "535/1500.0 loss: 0.279779274357177 \n",
      "Epoch:  1\n",
      "536/1500.0 loss: 0.2793775606324664 \n",
      "Epoch:  1\n",
      "537/1500.0 loss: 0.2790592326038278 \n",
      "Epoch:  1\n",
      "538/1500.0 loss: 0.2786869277248024 \n",
      "Epoch:  1\n",
      "539/1500.0 loss: 0.2783578956499696 \n",
      "Epoch:  1\n",
      "540/1500.0 loss: 0.2779663827704083 \n",
      "Epoch:  1\n",
      "541/1500.0 loss: 0.27759804291396345 \n",
      "Epoch:  1\n",
      "542/1500.0 loss: 0.2773450864187371 \n",
      "Epoch:  1\n",
      "543/1500.0 loss: 0.27695604618501796 \n",
      "Epoch:  1\n",
      "544/1500.0 loss: 0.2765727607960548 \n",
      "Epoch:  1\n",
      "545/1500.0 loss: 0.2761799866954486 \n",
      "Epoch:  1\n",
      "546/1500.0 loss: 0.2757562171374967 \n",
      "Epoch:  1\n",
      "547/1500.0 loss: 0.27538499858121585 \n",
      "Epoch:  1\n",
      "548/1500.0 loss: 0.2749775813685523 \n",
      "Epoch:  1\n",
      "549/1500.0 loss: 0.2745657725428993 \n",
      "Epoch:  1\n",
      "550/1500.0 loss: 0.2742423124530246 \n",
      "Epoch:  1\n",
      "551/1500.0 loss: 0.27383520450793963 \n",
      "Epoch:  1\n",
      "552/1500.0 loss: 0.2734959781183364 \n",
      "Epoch:  1\n",
      "553/1500.0 loss: 0.273101184456626 \n",
      "Epoch:  1\n",
      "554/1500.0 loss: 0.2726951392652752 \n",
      "Epoch:  1\n",
      "555/1500.0 loss: 0.27230108478408066 \n",
      "Epoch:  1\n",
      "556/1500.0 loss: 0.27194152276167105 \n",
      "Epoch:  1\n",
      "557/1500.0 loss: 0.27154526948982244 \n",
      "Epoch:  1\n",
      "558/1500.0 loss: 0.27120468581565166 \n",
      "Epoch:  1\n",
      "559/1500.0 loss: 0.2708149371003466 \n",
      "Epoch:  1\n",
      "560/1500.0 loss: 0.2704705931445494 \n",
      "Epoch:  1\n",
      "561/1500.0 loss: 0.2700932701565723 \n",
      "Epoch:  1\n",
      "562/1500.0 loss: 0.26974332904969184 \n",
      "Epoch:  1\n",
      "563/1500.0 loss: 0.2693798920958706 \n",
      "Epoch:  1\n",
      "564/1500.0 loss: 0.26898757907009757 \n",
      "Epoch:  1\n",
      "565/1500.0 loss: 0.26865290390334157 \n",
      "Epoch:  1\n",
      "566/1500.0 loss: 0.2682581844310912 \n",
      "Epoch:  1\n",
      "567/1500.0 loss: 0.26794832892401116 \n",
      "Epoch:  1\n",
      "568/1500.0 loss: 0.2675934407879682 \n",
      "Epoch:  1\n",
      "569/1500.0 loss: 0.26733517329159534 \n",
      "Epoch:  1\n",
      "570/1500.0 loss: 0.26701213048865624 \n",
      "Epoch:  1\n",
      "571/1500.0 loss: 0.2667077479141575 \n",
      "Epoch:  1\n",
      "572/1500.0 loss: 0.26632353326673075 \n",
      "Epoch:  1\n",
      "573/1500.0 loss: 0.2659400484495462 \n",
      "Epoch:  1\n",
      "574/1500.0 loss: 0.26569834027601325 \n",
      "Epoch:  1\n",
      "575/1500.0 loss: 0.2653271608869545 \n",
      "Epoch:  1\n",
      "576/1500.0 loss: 0.26514161272907383 \n",
      "Epoch:  1\n",
      "577/1500.0 loss: 0.26482811426440944 \n",
      "Epoch:  1\n",
      "578/1500.0 loss: 0.2644712136984386 \n",
      "Epoch:  1\n",
      "579/1500.0 loss: 0.26416499294212153 \n",
      "Epoch:  1\n",
      "580/1500.0 loss: 0.2638587158449033 \n",
      "Epoch:  1\n",
      "581/1500.0 loss: 0.264092547306951 \n",
      "Epoch:  1\n",
      "582/1500.0 loss: 0.26374106211380116 \n",
      "Epoch:  1\n",
      "583/1500.0 loss: 0.263390084613778 \n",
      "Epoch:  1\n",
      "584/1500.0 loss: 0.26301926592221625 \n",
      "Epoch:  1\n",
      "585/1500.0 loss: 0.26263495410693993 \n",
      "Epoch:  1\n",
      "586/1500.0 loss: 0.2622901250114839 \n",
      "Epoch:  1\n",
      "587/1500.0 loss: 0.2628539792661156 \n",
      "Epoch:  1\n",
      "588/1500.0 loss: 0.26256091076823773 \n",
      "Epoch:  1\n",
      "589/1500.0 loss: 0.26223984778685083 \n",
      "Epoch:  1\n",
      "590/1500.0 loss: 0.26186432406407123 \n",
      "Epoch:  1\n",
      "591/1500.0 loss: 0.26158095424919314 \n",
      "Epoch:  1\n",
      "592/1500.0 loss: 0.2612445339698715 \n",
      "Epoch:  1\n",
      "593/1500.0 loss: 0.26092781277643107 \n",
      "Epoch:  1\n",
      "594/1500.0 loss: 0.26060639455163176 \n",
      "Epoch:  1\n",
      "595/1500.0 loss: 0.260306362143949 \n",
      "Epoch:  1\n",
      "596/1500.0 loss: 0.25996583045602245 \n",
      "Epoch:  1\n",
      "597/1500.0 loss: 0.2596358256632568 \n",
      "Epoch:  1\n",
      "598/1500.0 loss: 0.2593216915647554 \n",
      "Epoch:  1\n",
      "599/1500.0 loss: 0.25952497141435743 \n",
      "Epoch:  1\n",
      "600/1500.0 loss: 0.2592592800652822 \n",
      "Epoch:  1\n",
      "601/1500.0 loss: 0.2589500920778988 \n",
      "Epoch:  1\n",
      "602/1500.0 loss: 0.2585962098740523 \n",
      "Epoch:  1\n",
      "603/1500.0 loss: 0.25824771588976614 \n",
      "Epoch:  1\n",
      "604/1500.0 loss: 0.25791294034724394 \n",
      "Epoch:  1\n",
      "605/1500.0 loss: 0.25757657462983047 \n",
      "Epoch:  1\n",
      "606/1500.0 loss: 0.2572280205724856 \n",
      "Epoch:  1\n",
      "607/1500.0 loss: 0.25689450552147863 \n",
      "Epoch:  1\n",
      "608/1500.0 loss: 0.2566145604051197 \n",
      "Epoch:  1\n",
      "609/1500.0 loss: 0.25628772076891093 \n",
      "Epoch:  1\n",
      "610/1500.0 loss: 0.25594707494891217 \n",
      "Epoch:  1\n",
      "611/1500.0 loss: 0.25558796072123097 \n",
      "Epoch:  1\n",
      "612/1500.0 loss: 0.25530152752096075 \n",
      "Epoch:  1\n",
      "613/1500.0 loss: 0.25501873012911225 \n",
      "Epoch:  1\n",
      "614/1500.0 loss: 0.2547723238545705 \n",
      "Epoch:  1\n",
      "615/1500.0 loss: 0.2544723394653433 \n",
      "Epoch:  1\n",
      "616/1500.0 loss: 0.2541294794596092 \n",
      "Epoch:  1\n",
      "617/1500.0 loss: 0.2537993474179294 \n",
      "Epoch:  1\n",
      "618/1500.0 loss: 0.2535373467428426 \n",
      "Epoch:  1\n",
      "619/1500.0 loss: 0.25326456014187104 \n",
      "Epoch:  1\n",
      "620/1500.0 loss: 0.25293129555365124 \n",
      "Epoch:  1\n",
      "621/1500.0 loss: 0.252583451024062 \n",
      "Epoch:  1\n",
      "622/1500.0 loss: 0.2522562253939206 \n",
      "Epoch:  1\n",
      "623/1500.0 loss: 0.2519206560563105 \n",
      "Epoch:  1\n",
      "624/1500.0 loss: 0.25158905470371246 \n",
      "Epoch:  1\n",
      "625/1500.0 loss: 0.2512446971544728 \n",
      "Epoch:  1\n",
      "626/1500.0 loss: 0.25098131161533666 \n",
      "Epoch:  1\n",
      "627/1500.0 loss: 0.2506972067236046 \n",
      "Epoch:  1\n",
      "628/1500.0 loss: 0.2504053493644835 \n",
      "Epoch:  1\n",
      "629/1500.0 loss: 0.2500878546091299 \n",
      "Epoch:  1\n",
      "630/1500.0 loss: 0.24979408317955473 \n",
      "Epoch:  1\n",
      "631/1500.0 loss: 0.24947074952806475 \n",
      "Epoch:  1\n",
      "632/1500.0 loss: 0.24917433898760621 \n",
      "Epoch:  1\n",
      "633/1500.0 loss: 0.24888210538598454 \n",
      "Epoch:  1\n",
      "634/1500.0 loss: 0.24859808939765757 \n",
      "Epoch:  1\n",
      "635/1500.0 loss: 0.24834430123439188 \n",
      "Epoch:  1\n",
      "636/1500.0 loss: 0.24807409556755092 \n",
      "Epoch:  1\n",
      "637/1500.0 loss: 0.24775647540170945 \n",
      "Epoch:  1\n",
      "638/1500.0 loss: 0.2474876977678196 \n",
      "Epoch:  1\n",
      "639/1500.0 loss: 0.24719109679572285 \n",
      "Epoch:  1\n",
      "640/1500.0 loss: 0.2468899541858485 \n",
      "Epoch:  1\n",
      "641/1500.0 loss: 0.24659618561814692 \n",
      "Epoch:  1\n",
      "642/1500.0 loss: 0.24628459388161336 \n",
      "Epoch:  1\n",
      "643/1500.0 loss: 0.24595224005835398 \n",
      "Epoch:  1\n",
      "644/1500.0 loss: 0.24563119386633236 \n",
      "Epoch:  1\n",
      "645/1500.0 loss: 0.24535553277853658 \n",
      "Epoch:  1\n",
      "646/1500.0 loss: 0.2450482532773541 \n",
      "Epoch:  1\n",
      "647/1500.0 loss: 0.24471472635186842 \n",
      "Epoch:  1\n",
      "648/1500.0 loss: 0.24439051047897395 \n",
      "Epoch:  1\n",
      "649/1500.0 loss: 0.24408463628532795 \n",
      "Epoch:  1\n",
      "650/1500.0 loss: 0.24384344937122454 \n",
      "Epoch:  1\n",
      "651/1500.0 loss: 0.2435193931415357 \n",
      "Epoch:  1\n",
      "652/1500.0 loss: 0.24320994716017846 \n",
      "Epoch:  1\n",
      "653/1500.0 loss: 0.24294440302747197 \n",
      "Epoch:  1\n",
      "654/1500.0 loss: 0.24262437440796208 \n",
      "Epoch:  1\n",
      "655/1500.0 loss: 0.2423155231134421 \n",
      "Epoch:  1\n",
      "656/1500.0 loss: 0.24201903819663612 \n",
      "Epoch:  1\n",
      "657/1500.0 loss: 0.2417122786185254 \n",
      "Epoch:  1\n",
      "658/1500.0 loss: 0.24142174446200654 \n",
      "Epoch:  1\n",
      "659/1500.0 loss: 0.24116218730976635 \n",
      "Epoch:  1\n",
      "660/1500.0 loss: 0.2408513472064676 \n",
      "Epoch:  1\n",
      "661/1500.0 loss: 0.24058565435216417 \n",
      "Epoch:  1\n",
      "662/1500.0 loss: 0.24034163212827878 \n",
      "Epoch:  1\n",
      "663/1500.0 loss: 0.24005132065581 \n",
      "Epoch:  1\n",
      "664/1500.0 loss: 0.23975916744903067 \n",
      "Epoch:  1\n",
      "665/1500.0 loss: 0.23946850517255677 \n",
      "Epoch:  1\n",
      "666/1500.0 loss: 0.23917373573348888 \n",
      "Epoch:  1\n",
      "667/1500.0 loss: 0.23886624207541704 \n",
      "Epoch:  1\n",
      "668/1500.0 loss: 0.23857397295155958 \n",
      "Epoch:  1\n",
      "669/1500.0 loss: 0.2382800479405629 \n",
      "Epoch:  1\n",
      "670/1500.0 loss: 0.23797518550938804 \n",
      "Epoch:  1\n",
      "671/1500.0 loss: 0.23767345444953425 \n",
      "Epoch:  1\n",
      "672/1500.0 loss: 0.23739679019626944 \n",
      "Epoch:  1\n",
      "673/1500.0 loss: 0.23712308923451325 \n",
      "Epoch:  1\n",
      "674/1500.0 loss: 0.23682592521939014 \n",
      "Epoch:  1\n",
      "675/1500.0 loss: 0.23656975509620895 \n",
      "Epoch:  1\n",
      "676/1500.0 loss: 0.23627836226129373 \n",
      "Epoch:  1\n",
      "677/1500.0 loss: 0.23600925032906564 \n",
      "Epoch:  1\n",
      "678/1500.0 loss: 0.2357393363531849 \n",
      "Epoch:  1\n",
      "679/1500.0 loss: 0.23545824516400257 \n",
      "Epoch:  1\n",
      "680/1500.0 loss: 0.23519492571935516 \n",
      "Epoch:  1\n",
      "681/1500.0 loss: 0.23489395940616245 \n",
      "Epoch:  1\n",
      "682/1500.0 loss: 0.2346136514806512 \n",
      "Epoch:  1\n",
      "683/1500.0 loss: 0.2343164183204852 \n",
      "Epoch:  1\n",
      "684/1500.0 loss: 0.23555505216176056 \n",
      "Epoch:  1\n",
      "685/1500.0 loss: 0.23528378631420022 \n",
      "Epoch:  1\n",
      "686/1500.0 loss: 0.23501661018871065 \n",
      "Epoch:  1\n",
      "687/1500.0 loss: 0.23477691001811085 \n",
      "Epoch:  1\n",
      "688/1500.0 loss: 0.2344815918097086 \n",
      "Epoch:  1\n",
      "689/1500.0 loss: 0.23419980967984252 \n",
      "Epoch:  1\n",
      "690/1500.0 loss: 0.23394789666681404 \n",
      "Epoch:  1\n",
      "691/1500.0 loss: 0.23369316496439493 \n",
      "Epoch:  1\n",
      "692/1500.0 loss: 0.23345142429019897 \n",
      "Epoch:  1\n",
      "693/1500.0 loss: 0.23320628037295096 \n",
      "Epoch:  1\n",
      "694/1500.0 loss: 0.23291565919522758 \n",
      "Epoch:  1\n",
      "695/1500.0 loss: 0.23264950319546565 \n",
      "Epoch:  1\n",
      "696/1500.0 loss: 0.2323949137272332 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "697/1500.0 loss: 0.23211127254354066 \n",
      "Epoch:  1\n",
      "698/1500.0 loss: 0.23184200616097758 \n",
      "Epoch:  1\n",
      "699/1500.0 loss: 0.23158919370600156 \n",
      "Epoch:  1\n",
      "700/1500.0 loss: 0.23318111762595756 \n",
      "Epoch:  1\n",
      "701/1500.0 loss: 0.23291869897214945 \n",
      "Epoch:  1\n",
      "702/1500.0 loss: 0.23278035828115082 \n",
      "Epoch:  1\n",
      "703/1500.0 loss: 0.23249826664422554 \n",
      "Epoch:  1\n",
      "704/1500.0 loss: 0.23227622086803118 \n",
      "Epoch:  1\n",
      "705/1500.0 loss: 0.23201594437886736 \n",
      "Epoch:  1\n",
      "706/1500.0 loss: 0.23173125583251683 \n",
      "Epoch:  1\n",
      "707/1500.0 loss: 0.2314745106544914 \n",
      "Epoch:  1\n",
      "708/1500.0 loss: 0.23121324928979192 \n",
      "Epoch:  1\n",
      "709/1500.0 loss: 0.23095628345568836 \n",
      "Epoch:  1\n",
      "710/1500.0 loss: 0.23071006160234683 \n",
      "Epoch:  1\n",
      "711/1500.0 loss: 0.23042808516798646 \n",
      "Epoch:  1\n",
      "712/1500.0 loss: 0.2301908948838836 \n",
      "Epoch:  1\n",
      "713/1500.0 loss: 0.22992425018801493 \n",
      "Epoch:  1\n",
      "714/1500.0 loss: 0.22964215928857976 \n",
      "Epoch:  1\n",
      "715/1500.0 loss: 0.22937977728147746 \n",
      "Epoch:  1\n",
      "716/1500.0 loss: 0.22911601237214926 \n",
      "Epoch:  1\n",
      "717/1500.0 loss: 0.22885626840371442 \n",
      "Epoch:  1\n",
      "718/1500.0 loss: 0.22861054374917988 \n",
      "Epoch:  1\n",
      "719/1500.0 loss: 0.22841086476627323 \n",
      "Epoch:  1\n",
      "720/1500.0 loss: 0.2281564734359472 \n",
      "Epoch:  1\n",
      "721/1500.0 loss: 0.22791060783134107 \n",
      "Epoch:  1\n",
      "722/1500.0 loss: 0.22776568557855828 \n",
      "Epoch:  1\n",
      "723/1500.0 loss: 0.22752252158847797 \n",
      "Epoch:  1\n",
      "724/1500.0 loss: 0.22726091139275453 \n",
      "Epoch:  1\n",
      "725/1500.0 loss: 0.227005550976504 \n",
      "Epoch:  1\n",
      "726/1500.0 loss: 0.22680638971875589 \n",
      "Epoch:  1\n",
      "727/1500.0 loss: 0.22663982769801885 \n",
      "Epoch:  1\n",
      "728/1500.0 loss: 0.22637138981244365 \n",
      "Epoch:  1\n",
      "729/1500.0 loss: 0.2261001520598792 \n",
      "Epoch:  1\n",
      "730/1500.0 loss: 0.22583274332049688 \n",
      "Epoch:  1\n",
      "731/1500.0 loss: 0.22556634960553604 \n",
      "Epoch:  1\n",
      "732/1500.0 loss: 0.22531653463708345 \n",
      "Epoch:  1\n",
      "733/1500.0 loss: 0.2250838624516487 \n",
      "Epoch:  1\n",
      "734/1500.0 loss: 0.22486850178109952 \n",
      "Epoch:  1\n",
      "735/1500.0 loss: 0.22463968003664733 \n",
      "Epoch:  1\n",
      "736/1500.0 loss: 0.2243949109852678 \n",
      "Epoch:  1\n",
      "737/1500.0 loss: 0.22415352890616266 \n",
      "Epoch:  1\n",
      "738/1500.0 loss: 0.2239128001745039 \n",
      "Epoch:  1\n",
      "739/1500.0 loss: 0.22368148530304835 \n",
      "Epoch:  1\n",
      "740/1500.0 loss: 0.22343340959254143 \n",
      "Epoch:  1\n",
      "741/1500.0 loss: 0.22318690886967024 \n",
      "Epoch:  1\n",
      "742/1500.0 loss: 0.22296110881820902 \n",
      "Epoch:  1\n",
      "743/1500.0 loss: 0.22272923867899164 \n",
      "Epoch:  1\n",
      "744/1500.0 loss: 0.22246104126308588 \n",
      "Epoch:  1\n",
      "745/1500.0 loss: 0.22222041566893658 \n",
      "Epoch:  1\n",
      "746/1500.0 loss: 0.22196650389367478 \n",
      "Epoch:  1\n",
      "747/1500.0 loss: 0.22172980507546886 \n",
      "Epoch:  1\n",
      "748/1500.0 loss: 0.22149367828434396 \n",
      "Epoch:  1\n",
      "749/1500.0 loss: 0.22125320359567802 \n",
      "Epoch:  1\n",
      "750/1500.0 loss: 0.22100399771876406 \n",
      "Epoch:  1\n",
      "751/1500.0 loss: 0.22077389725265986 \n",
      "Epoch:  1\n",
      "752/1500.0 loss: 0.22056738139781978 \n",
      "Epoch:  1\n",
      "753/1500.0 loss: 0.22031363936027498 \n",
      "Epoch:  1\n",
      "754/1500.0 loss: 0.2200781198156788 \n",
      "Epoch:  1\n",
      "755/1500.0 loss: 0.21983295469421638 \n",
      "Epoch:  1\n",
      "756/1500.0 loss: 0.21960714034480258 \n",
      "Epoch:  1\n",
      "757/1500.0 loss: 0.21936768876010243 \n",
      "Epoch:  1\n",
      "758/1500.0 loss: 0.21919004874100248 \n",
      "Epoch:  1\n",
      "759/1500.0 loss: 0.21894899217754996 \n",
      "Epoch:  1\n",
      "760/1500.0 loss: 0.21870433730311917 \n",
      "Epoch:  1\n",
      "761/1500.0 loss: 0.21847304691294125 \n",
      "Epoch:  1\n",
      "762/1500.0 loss: 0.21822695019575591 \n",
      "Epoch:  1\n",
      "763/1500.0 loss: 0.21798089544742286 \n",
      "Epoch:  1\n",
      "764/1500.0 loss: 0.21773770634888434 \n",
      "Epoch:  1\n",
      "765/1500.0 loss: 0.21750794243378754 \n",
      "Epoch:  1\n",
      "766/1500.0 loss: 0.21725981306367234 \n",
      "Epoch:  1\n",
      "767/1500.0 loss: 0.22095325035964683 \n",
      "Epoch:  1\n",
      "768/1500.0 loss: 0.220722809271652 \n",
      "Epoch:  1\n",
      "769/1500.0 loss: 0.22049340843525414 \n",
      "Epoch:  1\n",
      "770/1500.0 loss: 0.22024065990305364 \n",
      "Epoch:  1\n",
      "771/1500.0 loss: 0.22016421508362488 \n",
      "Epoch:  1\n",
      "772/1500.0 loss: 0.2199213999127162 \n",
      "Epoch:  1\n",
      "773/1500.0 loss: 0.2216866862784484 \n",
      "Epoch:  1\n",
      "774/1500.0 loss: 0.2214555362996555 \n",
      "Epoch:  1\n",
      "775/1500.0 loss: 0.22120860586250105 \n",
      "Epoch:  1\n",
      "776/1500.0 loss: 0.22102301641148028 \n",
      "Epoch:  1\n",
      "777/1500.0 loss: 0.22078756508261807 \n",
      "Epoch:  1\n",
      "778/1500.0 loss: 0.22056874703132906 \n",
      "Epoch:  1\n",
      "779/1500.0 loss: 0.2203147360481895 \n",
      "Epoch:  1\n",
      "780/1500.0 loss: 0.2200707888204447 \n",
      "Epoch:  1\n",
      "781/1500.0 loss: 0.21986814747419198 \n",
      "Epoch:  1\n",
      "782/1500.0 loss: 0.21974361248285834 \n",
      "Epoch:  1\n",
      "783/1500.0 loss: 0.2195546629230435 \n",
      "Epoch:  1\n",
      "784/1500.0 loss: 0.22137634077459384 \n",
      "Epoch:  1\n",
      "785/1500.0 loss: 0.22113964950746404 \n",
      "Epoch:  1\n",
      "786/1500.0 loss: 0.2208998574859911 \n",
      "Epoch:  1\n",
      "787/1500.0 loss: 0.2206748340865077 \n",
      "Epoch:  1\n",
      "788/1500.0 loss: 0.22055035503758225 \n",
      "Epoch:  1\n",
      "789/1500.0 loss: 0.22034146260422996 \n",
      "Epoch:  1\n",
      "790/1500.0 loss: 0.22285720961246117 \n",
      "Epoch:  1\n",
      "791/1500.0 loss: 0.22263956938239962 \n",
      "Epoch:  1\n",
      "792/1500.0 loss: 0.22239872869597407 \n",
      "Epoch:  1\n",
      "793/1500.0 loss: 0.22216866152731687 \n",
      "Epoch:  1\n",
      "794/1500.0 loss: 0.22192859823505084 \n",
      "Epoch:  1\n",
      "795/1500.0 loss: 0.22184627403472387 \n",
      "Epoch:  1\n",
      "796/1500.0 loss: 0.22162984593898769 \n",
      "Epoch:  1\n",
      "797/1500.0 loss: 0.22145193869383412 \n",
      "Epoch:  1\n",
      "798/1500.0 loss: 0.2212045273052363 \n",
      "Epoch:  1\n",
      "799/1500.0 loss: 0.22101468165870755 \n",
      "Epoch:  1\n",
      "800/1500.0 loss: 0.2207994692994935 \n",
      "Epoch:  1\n",
      "801/1500.0 loss: 0.22060061508134712 \n",
      "Epoch:  1\n",
      "802/1500.0 loss: 0.22036314277375027 \n",
      "Epoch:  1\n",
      "803/1500.0 loss: 0.22012412887233407 \n",
      "Epoch:  1\n",
      "804/1500.0 loss: 0.21991786572688854 \n",
      "Epoch:  1\n",
      "805/1500.0 loss: 0.2196781119821644 \n",
      "Epoch:  1\n",
      "806/1500.0 loss: 0.21944896774562686 \n",
      "Epoch:  1\n",
      "807/1500.0 loss: 0.2192047532799995 \n",
      "Epoch:  1\n",
      "808/1500.0 loss: 0.2190083993532049 \n",
      "Epoch:  1\n",
      "809/1500.0 loss: 0.21878109693665196 \n",
      "Epoch:  1\n",
      "810/1500.0 loss: 0.21855546616973257 \n",
      "Epoch:  1\n",
      "811/1500.0 loss: 0.21840490324863146 \n",
      "Epoch:  1\n",
      "812/1500.0 loss: 0.2181899735147333 \n",
      "Epoch:  1\n",
      "813/1500.0 loss: 0.21798357360879606 \n",
      "Epoch:  1\n",
      "814/1500.0 loss: 0.2177537316879246 \n",
      "Epoch:  1\n",
      "815/1500.0 loss: 0.2175631669313446 \n",
      "Epoch:  1\n",
      "816/1500.0 loss: 0.2173469717838919 \n",
      "Epoch:  1\n",
      "817/1500.0 loss: 0.21713774413107223 \n",
      "Epoch:  1\n",
      "818/1500.0 loss: 0.21691677373207388 \n",
      "Epoch:  1\n",
      "819/1500.0 loss: 0.21671966079895089 \n",
      "Epoch:  1\n",
      "820/1500.0 loss: 0.21648764576939877 \n",
      "Epoch:  1\n",
      "821/1500.0 loss: 0.2162684503729725 \n",
      "Epoch:  1\n",
      "822/1500.0 loss: 0.21605975080602877 \n",
      "Epoch:  1\n",
      "823/1500.0 loss: 0.2158488769432331 \n",
      "Epoch:  1\n",
      "824/1500.0 loss: 0.21566132207937314 \n",
      "Epoch:  1\n",
      "825/1500.0 loss: 0.2154473038660881 \n",
      "Epoch:  1\n",
      "826/1500.0 loss: 0.21522481466768514 \n",
      "Epoch:  1\n",
      "827/1500.0 loss: 0.21511408856930436 \n",
      "Epoch:  1\n",
      "828/1500.0 loss: 0.21489290185092946 \n",
      "Epoch:  1\n",
      "829/1500.0 loss: 0.21468963091856386 \n",
      "Epoch:  1\n",
      "830/1500.0 loss: 0.2144943258728469 \n",
      "Epoch:  1\n",
      "831/1500.0 loss: 0.2143248538106071 \n",
      "Epoch:  1\n",
      "832/1500.0 loss: 0.21411818030456892 \n",
      "Epoch:  1\n",
      "833/1500.0 loss: 0.21389522361490937 \n",
      "Epoch:  1\n",
      "834/1500.0 loss: 0.21373573352476793 \n",
      "Epoch:  1\n",
      "835/1500.0 loss: 0.21352386739301055 \n",
      "Epoch:  1\n",
      "836/1500.0 loss: 0.21330305517583267 \n",
      "Epoch:  1\n",
      "837/1500.0 loss: 0.2131181021947814 \n",
      "Epoch:  1\n",
      "838/1500.0 loss: 0.21289956298378143 \n",
      "Epoch:  1\n",
      "839/1500.0 loss: 0.2126898057049229 \n",
      "Epoch:  1\n",
      "840/1500.0 loss: 0.21247308875581386 \n",
      "Epoch:  1\n",
      "841/1500.0 loss: 0.21225551635053477 \n",
      "Epoch:  1\n",
      "842/1500.0 loss: 0.21204145697043814 \n",
      "Epoch:  1\n",
      "843/1500.0 loss: 0.21182584971789784 \n",
      "Epoch:  1\n",
      "844/1500.0 loss: 0.21162120902238513 \n",
      "Epoch:  1\n",
      "845/1500.0 loss: 0.21141916711156392 \n",
      "Epoch:  1\n",
      "846/1500.0 loss: 0.21120048601976393 \n",
      "Epoch:  1\n",
      "847/1500.0 loss: 0.21100425817740132 \n",
      "Epoch:  1\n",
      "848/1500.0 loss: 0.21080083505758407 \n",
      "Epoch:  1\n",
      "849/1500.0 loss: 0.21058249521343148 \n",
      "Epoch:  1\n",
      "850/1500.0 loss: 0.21037358491212024 \n",
      "Epoch:  1\n",
      "851/1500.0 loss: 0.2101891983274213 \n",
      "Epoch:  1\n",
      "852/1500.0 loss: 0.20998179952746118 \n",
      "Epoch:  1\n",
      "853/1500.0 loss: 0.20980274910652527 \n",
      "Epoch:  1\n",
      "854/1500.0 loss: 0.20959515969394243 \n",
      "Epoch:  1\n",
      "855/1500.0 loss: 0.20943884070631918 \n",
      "Epoch:  1\n",
      "856/1500.0 loss: 0.20923711785062052 \n",
      "Epoch:  1\n",
      "857/1500.0 loss: 0.20903454185626308 \n",
      "Epoch:  1\n",
      "858/1500.0 loss: 0.20882912813680413 \n",
      "Epoch:  1\n",
      "859/1500.0 loss: 0.20861705439598408 \n",
      "Epoch:  1\n",
      "860/1500.0 loss: 0.20841157085258993 \n",
      "Epoch:  1\n",
      "861/1500.0 loss: 0.2082143983892284 \n",
      "Epoch:  1\n",
      "862/1500.0 loss: 0.20802436936279783 \n",
      "Epoch:  1\n",
      "863/1500.0 loss: 0.20783729475483093 \n",
      "Epoch:  1\n",
      "864/1500.0 loss: 0.20763397054219176 \n",
      "Epoch:  1\n",
      "865/1500.0 loss: 0.20741666713191786 \n",
      "Epoch:  1\n",
      "866/1500.0 loss: 0.20721438640112008 \n",
      "Epoch:  1\n",
      "867/1500.0 loss: 0.20700894841443626 \n",
      "Epoch:  1\n",
      "868/1500.0 loss: 0.20680857756495544 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "869/1500.0 loss: 0.20660863236320773 \n",
      "Epoch:  1\n",
      "870/1500.0 loss: 0.20641020265644167 \n",
      "Epoch:  1\n",
      "871/1500.0 loss: 0.2062024156981652 \n",
      "Epoch:  1\n",
      "872/1500.0 loss: 0.2060674505493895 \n",
      "Epoch:  1\n",
      "873/1500.0 loss: 0.2058619129571646 \n",
      "Epoch:  1\n",
      "874/1500.0 loss: 0.20565040209037916 \n",
      "Epoch:  1\n",
      "875/1500.0 loss: 0.20543951196510973 \n",
      "Epoch:  1\n",
      "876/1500.0 loss: 0.205258100560124 \n",
      "Epoch:  1\n",
      "877/1500.0 loss: 0.2050685780844174 \n",
      "Epoch:  1\n",
      "878/1500.0 loss: 0.20488053651164212 \n",
      "Epoch:  1\n",
      "879/1500.0 loss: 0.2046866959532384 \n",
      "Epoch:  1\n",
      "880/1500.0 loss: 0.20448448773046424 \n",
      "Epoch:  1\n",
      "881/1500.0 loss: 0.20428439351368924 \n",
      "Epoch:  1\n",
      "882/1500.0 loss: 0.20408890625864842 \n",
      "Epoch:  1\n",
      "883/1500.0 loss: 0.20388858469110405 \n",
      "Epoch:  1\n",
      "884/1500.0 loss: 0.2036960655349796 \n",
      "Epoch:  1\n",
      "885/1500.0 loss: 0.20351415771663053 \n",
      "Epoch:  1\n",
      "886/1500.0 loss: 0.20334857959707667 \n",
      "Epoch:  1\n",
      "887/1500.0 loss: 0.20314820579186016 \n",
      "Epoch:  1\n",
      "888/1500.0 loss: 0.20297167053984644 \n",
      "Epoch:  1\n",
      "889/1500.0 loss: 0.20277216810147078 \n",
      "Epoch:  1\n",
      "890/1500.0 loss: 0.2025845571119008 \n",
      "Epoch:  1\n",
      "891/1500.0 loss: 0.20238490017431668 \n",
      "Epoch:  1\n",
      "892/1500.0 loss: 0.20219843378050664 \n",
      "Epoch:  1\n",
      "893/1500.0 loss: 0.20200589196277277 \n",
      "Epoch:  1\n",
      "894/1500.0 loss: 0.20180882888965768 \n",
      "Epoch:  1\n",
      "895/1500.0 loss: 0.20160891596086522 \n",
      "Epoch:  1\n",
      "896/1500.0 loss: 0.20141814769336014 \n",
      "Epoch:  1\n",
      "897/1500.0 loss: 0.20122346180368772 \n",
      "Epoch:  1\n",
      "898/1500.0 loss: 0.20104371290964732 \n",
      "Epoch:  1\n",
      "899/1500.0 loss: 0.20084848028504187 \n",
      "Epoch:  1\n",
      "900/1500.0 loss: 0.20066885788667613 \n",
      "Epoch:  1\n",
      "901/1500.0 loss: 0.20047347685590616 \n",
      "Epoch:  1\n",
      "902/1500.0 loss: 0.2002982514232793 \n",
      "Epoch:  1\n",
      "903/1500.0 loss: 0.20011083580207376 \n",
      "Epoch:  1\n",
      "904/1500.0 loss: 0.1999224212349943 \n",
      "Epoch:  1\n",
      "905/1500.0 loss: 0.1997303854341045 \n",
      "Epoch:  1\n",
      "906/1500.0 loss: 0.19953853881362385 \n",
      "Epoch:  1\n",
      "907/1500.0 loss: 0.19935607110941989 \n",
      "Epoch:  1\n",
      "908/1500.0 loss: 0.19916508367901917 \n",
      "Epoch:  1\n",
      "909/1500.0 loss: 0.19898211338895036 \n",
      "Epoch:  1\n",
      "910/1500.0 loss: 0.19882166913366017 \n",
      "Epoch:  1\n",
      "911/1500.0 loss: 0.19865110295359045 \n",
      "Epoch:  1\n",
      "912/1500.0 loss: 0.19846077066482026 \n",
      "Epoch:  1\n",
      "913/1500.0 loss: 0.1982812585708577 \n",
      "Epoch:  1\n",
      "914/1500.0 loss: 0.19812336074483525 \n",
      "Epoch:  1\n",
      "915/1500.0 loss: 0.19793307788336575 \n",
      "Epoch:  1\n",
      "916/1500.0 loss: 0.19774713160240598 \n",
      "Epoch:  1\n",
      "917/1500.0 loss: 0.19757551700079687 \n",
      "Epoch:  1\n",
      "918/1500.0 loss: 0.19740166953107155 \n",
      "Epoch:  1\n",
      "919/1500.0 loss: 0.19721521790665777 \n",
      "Epoch:  1\n",
      "920/1500.0 loss: 0.1970434717664113 \n",
      "Epoch:  1\n",
      "921/1500.0 loss: 0.19685323019219064 \n",
      "Epoch:  1\n",
      "922/1500.0 loss: 0.19668623482564287 \n",
      "Epoch:  1\n",
      "923/1500.0 loss: 0.19654415711131576 \n",
      "Epoch:  1\n",
      "924/1500.0 loss: 0.1963605617027025 \n",
      "Epoch:  1\n",
      "925/1500.0 loss: 0.19617912638530166 \n",
      "Epoch:  1\n",
      "926/1500.0 loss: 0.19600063061066367 \n",
      "Epoch:  1\n",
      "927/1500.0 loss: 0.1958120227028648 \n",
      "Epoch:  1\n",
      "928/1500.0 loss: 0.19562694292607746 \n",
      "Epoch:  1\n",
      "929/1500.0 loss: 0.1954420249608736 \n",
      "Epoch:  1\n",
      "930/1500.0 loss: 0.19526446524059157 \n",
      "Epoch:  1\n",
      "931/1500.0 loss: 0.19507923109313002 \n",
      "Epoch:  1\n",
      "932/1500.0 loss: 0.19491965890465762 \n",
      "Epoch:  1\n",
      "933/1500.0 loss: 0.19475185117490862 \n",
      "Epoch:  1\n",
      "934/1500.0 loss: 0.194646097610102 \n",
      "Epoch:  1\n",
      "935/1500.0 loss: 0.19446954536092523 \n",
      "Epoch:  1\n",
      "936/1500.0 loss: 0.19428849812863414 \n",
      "Epoch:  1\n",
      "937/1500.0 loss: 0.194137447847248 \n",
      "Epoch:  1\n",
      "938/1500.0 loss: 0.19395857474333245 \n",
      "Epoch:  1\n",
      "939/1500.0 loss: 0.19379601205322652 \n",
      "Epoch:  1\n",
      "940/1500.0 loss: 0.19363276915986974 \n",
      "Epoch:  1\n",
      "941/1500.0 loss: 0.19346481020069994 \n",
      "Epoch:  1\n",
      "942/1500.0 loss: 0.19328751320993154 \n",
      "Epoch:  1\n",
      "943/1500.0 loss: 0.19310702987891323 \n",
      "Epoch:  1\n",
      "944/1500.0 loss: 0.19295444442205645 \n",
      "Epoch:  1\n",
      "945/1500.0 loss: 0.1928006518596732 \n",
      "Epoch:  1\n",
      "946/1500.0 loss: 0.1926201272976153 \n",
      "Epoch:  1\n",
      "947/1500.0 loss: 0.1924608295630145 \n",
      "Epoch:  1\n",
      "948/1500.0 loss: 0.1922813851731752 \n",
      "Epoch:  1\n",
      "949/1500.0 loss: 0.19210015085770896 \n",
      "Epoch:  1\n",
      "950/1500.0 loss: 0.19192359621169439 \n",
      "Epoch:  1\n",
      "951/1500.0 loss: 0.19174434526573023 \n",
      "Epoch:  1\n",
      "952/1500.0 loss: 0.19158338289219273 \n",
      "Epoch:  1\n",
      "953/1500.0 loss: 0.19143312751458064 \n",
      "Epoch:  1\n",
      "954/1500.0 loss: 0.1912650199363213 \n",
      "Epoch:  1\n",
      "955/1500.0 loss: 0.19110030289856272 \n",
      "Epoch:  1\n",
      "956/1500.0 loss: 0.1909259592952711 \n",
      "Epoch:  1\n",
      "957/1500.0 loss: 0.19076351637102368 \n",
      "Epoch:  1\n",
      "958/1500.0 loss: 0.19059052491197373 \n",
      "Epoch:  1\n",
      "959/1500.0 loss: 0.19042418507742695 \n",
      "Epoch:  1\n",
      "960/1500.0 loss: 0.1902497276783951 \n",
      "Epoch:  1\n",
      "961/1500.0 loss: 0.1900826615480834 \n",
      "Epoch:  1\n",
      "962/1500.0 loss: 0.1899315202308902 \n",
      "Epoch:  1\n",
      "963/1500.0 loss: 0.18976131895425655 \n",
      "Epoch:  1\n",
      "964/1500.0 loss: 0.18958900232504997 \n",
      "Epoch:  1\n",
      "965/1500.0 loss: 0.1894307666849615 \n",
      "Epoch:  1\n",
      "966/1500.0 loss: 0.18927304102483494 \n",
      "Epoch:  1\n",
      "967/1500.0 loss: 0.1890977307757717 \n",
      "Epoch:  1\n",
      "968/1500.0 loss: 0.18892669725213565 \n",
      "Epoch:  1\n",
      "969/1500.0 loss: 0.18875727415200055 \n",
      "Epoch:  1\n",
      "970/1500.0 loss: 0.18858577745720115 \n",
      "Epoch:  1\n",
      "971/1500.0 loss: 0.1884131501505435 \n",
      "Epoch:  1\n",
      "972/1500.0 loss: 0.18824059669912352 \n",
      "Epoch:  1\n",
      "973/1500.0 loss: 0.18808167261976053 \n",
      "Epoch:  1\n",
      "974/1500.0 loss: 0.18791960052572765 \n",
      "Epoch:  1\n",
      "975/1500.0 loss: 0.18775603965833235 \n",
      "Epoch:  1\n",
      "976/1500.0 loss: 0.18758314200119328 \n",
      "Epoch:  1\n",
      "977/1500.0 loss: 0.18741324661272923 \n",
      "Epoch:  1\n",
      "978/1500.0 loss: 0.18725631722801797 \n",
      "Epoch:  1\n",
      "979/1500.0 loss: 0.18711106428230295 \n",
      "Epoch:  1\n",
      "980/1500.0 loss: 0.1869548080559292 \n",
      "Epoch:  1\n",
      "981/1500.0 loss: 0.18680288512145915 \n",
      "Epoch:  1\n",
      "982/1500.0 loss: 0.1866561706771928 \n",
      "Epoch:  1\n",
      "983/1500.0 loss: 0.1864843066456175 \n",
      "Epoch:  1\n",
      "984/1500.0 loss: 0.1863260949153434 \n",
      "Epoch:  1\n",
      "985/1500.0 loss: 0.18615913807091436 \n",
      "Epoch:  1\n",
      "986/1500.0 loss: 0.18600041585528077 \n",
      "Epoch:  1\n",
      "987/1500.0 loss: 0.1858348364824889 \n",
      "Epoch:  1\n",
      "988/1500.0 loss: 0.18566693571990373 \n",
      "Epoch:  1\n",
      "989/1500.0 loss: 0.18552454403705068 \n",
      "Epoch:  1\n",
      "990/1500.0 loss: 0.18536814432271675 \n",
      "Epoch:  1\n",
      "991/1500.0 loss: 0.18520100430149825 \n",
      "Epoch:  1\n",
      "992/1500.0 loss: 0.18503655569228342 \n",
      "Epoch:  1\n",
      "993/1500.0 loss: 0.18487449206779122 \n",
      "Epoch:  1\n",
      "994/1500.0 loss: 0.18471937713086906 \n",
      "Epoch:  1\n",
      "995/1500.0 loss: 0.1845637121589398 \n",
      "Epoch:  1\n",
      "996/1500.0 loss: 0.18440025972731136 \n",
      "Epoch:  1\n",
      "997/1500.0 loss: 0.18431614473357588 \n",
      "Epoch:  1\n",
      "998/1500.0 loss: 0.18415245456104581 \n",
      "Epoch:  1\n",
      "999/1500.0 loss: 0.18399669789895415 \n",
      "Epoch:  1\n",
      "1000/1500.0 loss: 0.18383593617805413 \n",
      "Epoch:  1\n",
      "1001/1500.0 loss: 0.18368441216134562 \n",
      "Epoch:  1\n",
      "1002/1500.0 loss: 0.18352343515675898 \n",
      "Epoch:  1\n",
      "1003/1500.0 loss: 0.18336988651412595 \n",
      "Epoch:  1\n",
      "1004/1500.0 loss: 0.18322548082478307 \n",
      "Epoch:  1\n",
      "1005/1500.0 loss: 0.18305976064709084 \n",
      "Epoch:  1\n",
      "1006/1500.0 loss: 0.18289788249166092 \n",
      "Epoch:  1\n",
      "1007/1500.0 loss: 0.18273676813410092 \n",
      "Epoch:  1\n",
      "1008/1500.0 loss: 0.18257867125471236 \n",
      "Epoch:  1\n",
      "1009/1500.0 loss: 0.1824205310185357 \n",
      "Epoch:  1\n",
      "1010/1500.0 loss: 0.18227041914734832 \n",
      "Epoch:  1\n",
      "1011/1500.0 loss: 0.1821238624498896 \n",
      "Epoch:  1\n",
      "1012/1500.0 loss: 0.18198489997561687 \n",
      "Epoch:  1\n",
      "1013/1500.0 loss: 0.1818294806123015 \n",
      "Epoch:  1\n",
      "1014/1500.0 loss: 0.18168740790025353 \n",
      "Epoch:  1\n",
      "1015/1500.0 loss: 0.1815347892147907 \n",
      "Epoch:  1\n",
      "1016/1500.0 loss: 0.18137351959401646 \n",
      "Epoch:  1\n",
      "1017/1500.0 loss: 0.18122693206492835 \n",
      "Epoch:  1\n",
      "1018/1500.0 loss: 0.1810708666956957 \n",
      "Epoch:  1\n",
      "1019/1500.0 loss: 0.180921020658285 \n",
      "Epoch:  1\n",
      "1020/1500.0 loss: 0.1807736581598247 \n",
      "Epoch:  1\n",
      "1021/1500.0 loss: 0.18064715121116365 \n",
      "Epoch:  1\n",
      "1022/1500.0 loss: 0.18048996073380477 \n",
      "Epoch:  1\n",
      "1023/1500.0 loss: 0.1803987392631825 \n",
      "Epoch:  1\n",
      "1024/1500.0 loss: 0.18024149882539017 \n",
      "Epoch:  1\n",
      "1025/1500.0 loss: 0.1800908303672546 \n",
      "Epoch:  1\n",
      "1026/1500.0 loss: 0.17994304651352772 \n",
      "Epoch:  1\n",
      "1027/1500.0 loss: 0.17979334664969535 \n",
      "Epoch:  1\n",
      "1028/1500.0 loss: 0.1796402071826196 \n",
      "Epoch:  1\n",
      "1029/1500.0 loss: 0.17948352961430272 \n",
      "Epoch:  1\n",
      "1030/1500.0 loss: 0.1793254715319141 \n",
      "Epoch:  1\n",
      "1031/1500.0 loss: 0.1791696018835371 \n",
      "Epoch:  1\n",
      "1032/1500.0 loss: 0.17901732365259068 \n",
      "Epoch:  1\n",
      "1033/1500.0 loss: 0.1788712811333846 \n",
      "Epoch:  1\n",
      "1034/1500.0 loss: 0.1787283500449525 \n",
      "Epoch:  1\n",
      "1035/1500.0 loss: 0.17858075380907842 \n",
      "Epoch:  1\n",
      "1036/1500.0 loss: 0.17844883798151892 \n",
      "Epoch:  1\n",
      "1037/1500.0 loss: 0.178299697921728 \n",
      "Epoch:  1\n",
      "1038/1500.0 loss: 0.17814860276203814 \n",
      "Epoch:  1\n",
      "1039/1500.0 loss: 0.17799184231553228 \n",
      "Epoch:  1\n",
      "1040/1500.0 loss: 0.1778457931741199 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "1041/1500.0 loss: 0.17769641385390467 \n",
      "Epoch:  1\n",
      "1042/1500.0 loss: 0.17754547736381582 \n",
      "Epoch:  1\n",
      "1043/1500.0 loss: 0.17747026890109496 \n",
      "Epoch:  1\n",
      "1044/1500.0 loss: 0.1773212382168861 \n",
      "Epoch:  1\n",
      "1045/1500.0 loss: 0.17718056505314478 \n",
      "Epoch:  1\n",
      "1046/1500.0 loss: 0.17703680050627835 \n",
      "Epoch:  1\n",
      "1047/1500.0 loss: 0.17688985344178917 \n",
      "Epoch:  1\n",
      "1048/1500.0 loss: 0.1767371834510559 \n",
      "Epoch:  1\n",
      "1049/1500.0 loss: 0.17658969770939578 \n",
      "Epoch:  1\n",
      "1050/1500.0 loss: 0.1764395706103911 \n",
      "Epoch:  1\n",
      "1051/1500.0 loss: 0.1762956491823772 \n",
      "Epoch:  1\n",
      "1052/1500.0 loss: 0.17615015932835518 \n",
      "Epoch:  1\n",
      "1053/1500.0 loss: 0.1760085651675766 \n",
      "Epoch:  1\n",
      "1054/1500.0 loss: 0.17585995185290468 \n",
      "Epoch:  1\n",
      "1055/1500.0 loss: 0.17571513624121013 \n",
      "Epoch:  1\n",
      "1056/1500.0 loss: 0.1755655404962705 \n",
      "Epoch:  1\n",
      "1057/1500.0 loss: 0.1754246187908663 \n",
      "Epoch:  1\n",
      "1058/1500.0 loss: 0.17528605466573108 \n",
      "Epoch:  1\n",
      "1059/1500.0 loss: 0.1751527869880621 \n",
      "Epoch:  1\n",
      "1060/1500.0 loss: 0.1750103353060129 \n",
      "Epoch:  1\n",
      "1061/1500.0 loss: 0.17486710462845484 \n",
      "Epoch:  1\n",
      "1062/1500.0 loss: 0.17471716371264137 \n",
      "Epoch:  1\n",
      "1063/1500.0 loss: 0.1745733757279253 \n",
      "Epoch:  1\n",
      "1064/1500.0 loss: 0.17442207302408458 \n",
      "Epoch:  1\n",
      "1065/1500.0 loss: 0.1742776233893356 \n",
      "Epoch:  1\n",
      "1066/1500.0 loss: 0.1741360664383387 \n",
      "Epoch:  1\n",
      "1067/1500.0 loss: 0.1740013367386556 \n",
      "Epoch:  1\n",
      "1068/1500.0 loss: 0.17385662861178838 \n",
      "Epoch:  1\n",
      "1069/1500.0 loss: 0.1737112377578758 \n",
      "Epoch:  1\n",
      "1070/1500.0 loss: 0.17356433835659735 \n",
      "Epoch:  1\n",
      "1071/1500.0 loss: 0.17342647834274388 \n",
      "Epoch:  1\n",
      "1072/1500.0 loss: 0.17328101362796972 \n",
      "Epoch:  1\n",
      "1073/1500.0 loss: 0.1731379804794557 \n",
      "Epoch:  1\n",
      "1074/1500.0 loss: 0.17304402418521256 \n",
      "Epoch:  1\n",
      "1075/1500.0 loss: 0.17290993292338205 \n",
      "Epoch:  1\n",
      "1076/1500.0 loss: 0.1727677043830023 \n",
      "Epoch:  1\n",
      "1077/1500.0 loss: 0.1726270329340228 \n",
      "Epoch:  1\n",
      "1078/1500.0 loss: 0.17248951363100207 \n",
      "Epoch:  1\n",
      "1079/1500.0 loss: 0.1723476084406246 \n",
      "Epoch:  1\n",
      "1080/1500.0 loss: 0.1722070333710721 \n",
      "Epoch:  1\n",
      "1081/1500.0 loss: 0.17206692056689074 \n",
      "Epoch:  1\n",
      "1082/1500.0 loss: 0.1719241048908506 \n",
      "Epoch:  1\n",
      "1083/1500.0 loss: 0.17179107602180507 \n",
      "Epoch:  1\n",
      "1084/1500.0 loss: 0.17164915590396812 \n",
      "Epoch:  1\n",
      "1085/1500.0 loss: 0.17150714986702054 \n",
      "Epoch:  1\n",
      "1086/1500.0 loss: 0.1713676202876053 \n",
      "Epoch:  1\n",
      "1087/1500.0 loss: 0.17122757551859488 \n",
      "Epoch:  1\n",
      "1088/1500.0 loss: 0.17108746173067224 \n",
      "Epoch:  1\n",
      "1089/1500.0 loss: 0.17094488102139546 \n",
      "Epoch:  1\n",
      "1090/1500.0 loss: 0.1708110989456421 \n",
      "Epoch:  1\n",
      "1091/1500.0 loss: 0.17067235242831266 \n",
      "Epoch:  1\n",
      "1092/1500.0 loss: 0.17053662775355338 \n",
      "Epoch:  1\n",
      "1093/1500.0 loss: 0.17039979781727332 \n",
      "Epoch:  1\n",
      "1094/1500.0 loss: 0.17026106854943243 \n",
      "Epoch:  1\n",
      "1095/1500.0 loss: 0.1701189679234717 \n",
      "Epoch:  1\n",
      "1096/1500.0 loss: 0.16998896844355676 \n",
      "Epoch:  1\n",
      "1097/1500.0 loss: 0.1698529003281316 \n",
      "Epoch:  1\n",
      "1098/1500.0 loss: 0.169715664959644 \n",
      "Epoch:  1\n",
      "1099/1500.0 loss: 0.16957628705877473 \n",
      "Epoch:  1\n",
      "1100/1500.0 loss: 0.16943839683259188 \n",
      "Epoch:  1\n",
      "1101/1500.0 loss: 0.1693082996914518 \n",
      "Epoch:  1\n",
      "1102/1500.0 loss: 0.1691756783921275 \n",
      "Epoch:  1\n",
      "1103/1500.0 loss: 0.16904099811074338 \n",
      "Epoch:  1\n",
      "1104/1500.0 loss: 0.16890788636511672 \n",
      "Epoch:  1\n",
      "1105/1500.0 loss: 0.1687706189211559 \n",
      "Epoch:  1\n",
      "1106/1500.0 loss: 0.16865983039271945 \n",
      "Epoch:  1\n",
      "1107/1500.0 loss: 0.1685291606309195 \n",
      "Epoch:  1\n",
      "1108/1500.0 loss: 0.1683978123566836 \n",
      "Epoch:  1\n",
      "1109/1500.0 loss: 0.16826094767615737 \n",
      "Epoch:  1\n",
      "1110/1500.0 loss: 0.1681296054993083 \n",
      "Epoch:  1\n",
      "1111/1500.0 loss: 0.16799210318324 \n",
      "Epoch:  1\n",
      "1112/1500.0 loss: 0.1678571327483183 \n",
      "Epoch:  1\n",
      "1113/1500.0 loss: 0.16772861073305245 \n",
      "Epoch:  1\n",
      "1114/1500.0 loss: 0.16760269894260463 \n",
      "Epoch:  1\n",
      "1115/1500.0 loss: 0.16746499222172526 \n",
      "Epoch:  1\n",
      "1116/1500.0 loss: 0.1673570748121747 \n",
      "Epoch:  1\n",
      "1117/1500.0 loss: 0.1672298018895556 \n",
      "Epoch:  1\n",
      "1118/1500.0 loss: 0.16710160665507023 \n",
      "Epoch:  1\n",
      "1119/1500.0 loss: 0.16697271591484814 \n",
      "Epoch:  1\n",
      "1120/1500.0 loss: 0.16685500783043233 \n",
      "Epoch:  1\n",
      "1121/1500.0 loss: 0.16672274146773544 \n",
      "Epoch:  1\n",
      "1122/1500.0 loss: 0.1672482701302079 \n",
      "Epoch:  1\n",
      "1123/1500.0 loss: 0.16712142476228686 \n",
      "Epoch:  1\n",
      "1124/1500.0 loss: 0.1669895395355092 \n",
      "Epoch:  1\n",
      "1125/1500.0 loss: 0.16685812030530156 \n",
      "Epoch:  1\n",
      "1126/1500.0 loss: 0.1667307678976996 \n",
      "Epoch:  1\n",
      "1127/1500.0 loss: 0.166598766536868 \n",
      "Epoch:  1\n",
      "1128/1500.0 loss: 0.16646487388819245 \n",
      "Epoch:  1\n",
      "1129/1500.0 loss: 0.16633262704909507 \n",
      "Epoch:  1\n",
      "1130/1500.0 loss: 0.16619962811137357 \n",
      "Epoch:  1\n",
      "1131/1500.0 loss: 0.1660653786732101 \n",
      "Epoch:  1\n",
      "1132/1500.0 loss: 0.1659319758166979 \n",
      "Epoch:  1\n",
      "1133/1500.0 loss: 0.1657989505387685 \n",
      "Epoch:  1\n",
      "1134/1500.0 loss: 0.16567214596031915 \n",
      "Epoch:  1\n",
      "1135/1500.0 loss: 0.16555853841849275 \n",
      "Epoch:  1\n",
      "1136/1500.0 loss: 0.1654553091834998 \n",
      "Epoch:  1\n",
      "1137/1500.0 loss: 0.16536898890621501 \n",
      "Epoch:  1\n",
      "1138/1500.0 loss: 0.16524062987214203 \n",
      "Epoch:  1\n",
      "1139/1500.0 loss: 0.16703780456119333 \n",
      "Epoch:  1\n",
      "1140/1500.0 loss: 0.1669101086694104 \n",
      "Epoch:  1\n",
      "1141/1500.0 loss: 0.16698195171116764 \n",
      "Epoch:  1\n",
      "1142/1500.0 loss: 0.16684995803571356 \n",
      "Epoch:  1\n",
      "1143/1500.0 loss: 0.1667188438171703 \n",
      "Epoch:  1\n",
      "1144/1500.0 loss: 0.1665928306611149 \n",
      "Epoch:  1\n",
      "1145/1500.0 loss: 0.166473105173545 \n",
      "Epoch:  1\n",
      "1146/1500.0 loss: 0.1663489742675486 \n",
      "Epoch:  1\n",
      "1147/1500.0 loss: 0.1662602998366586 \n",
      "Epoch:  1\n",
      "1148/1500.0 loss: 0.16613123556915135 \n",
      "Epoch:  1\n",
      "1149/1500.0 loss: 0.16599819443067132 \n",
      "Epoch:  1\n",
      "1150/1500.0 loss: 0.16586827405272853 \n",
      "Epoch:  1\n",
      "1151/1500.0 loss: 0.1657383597638626 \n",
      "Epoch:  1\n",
      "1152/1500.0 loss: 0.16561033562591487 \n",
      "Epoch:  1\n",
      "1153/1500.0 loss: 0.16548715596308405 \n",
      "Epoch:  1\n",
      "1154/1500.0 loss: 0.16535785732089311 \n",
      "Epoch:  1\n",
      "1155/1500.0 loss: 0.165233687367967 \n",
      "Epoch:  1\n",
      "1156/1500.0 loss: 0.16510663026752226 \n",
      "Epoch:  1\n",
      "1157/1500.0 loss: 0.1649817697010574 \n",
      "Epoch:  1\n",
      "1158/1500.0 loss: 0.16485442952964072 \n",
      "Epoch:  1\n",
      "1159/1500.0 loss: 0.16473040728235683 \n",
      "Epoch:  1\n",
      "1160/1500.0 loss: 0.1646063451251716 \n",
      "Epoch:  1\n",
      "1161/1500.0 loss: 0.16448068946981467 \n",
      "Epoch:  1\n",
      "1162/1500.0 loss: 0.16435542937707692 \n",
      "Epoch:  1\n",
      "1163/1500.0 loss: 0.16423172471945613 \n",
      "Epoch:  1\n",
      "1164/1500.0 loss: 0.1664706585896821 \n",
      "Epoch:  1\n",
      "1165/1500.0 loss: 0.16634245816455262 \n",
      "Epoch:  1\n",
      "1166/1500.0 loss: 0.16622245364647675 \n",
      "Epoch:  1\n",
      "1167/1500.0 loss: 0.16611049379372 \n",
      "Epoch:  1\n",
      "1168/1500.0 loss: 0.1659874364620567 \n",
      "Epoch:  1\n",
      "1169/1500.0 loss: 0.16586295841580145 \n",
      "Epoch:  1\n",
      "1170/1500.0 loss: 0.16573426533923075 \n",
      "Epoch:  1\n",
      "1171/1500.0 loss: 0.16561453205647755 \n",
      "Epoch:  1\n",
      "1172/1500.0 loss: 0.16551160815950777 \n",
      "Epoch:  1\n",
      "1173/1500.0 loss: 0.1654130858892743 \n",
      "Epoch:  1\n",
      "1174/1500.0 loss: 0.16531105496227108 \n",
      "Epoch:  1\n",
      "1175/1500.0 loss: 0.16524541246321459 \n",
      "Epoch:  1\n",
      "1176/1500.0 loss: 0.1651379133383969 \n",
      "Epoch:  1\n",
      "1177/1500.0 loss: 0.16501475645052127 \n",
      "Epoch:  1\n",
      "1178/1500.0 loss: 0.16492802560237807 \n",
      "Epoch:  1\n",
      "1179/1500.0 loss: 0.1648017942960674 \n",
      "Epoch:  1\n",
      "1180/1500.0 loss: 0.16469716864490563 \n",
      "Epoch:  1\n",
      "1181/1500.0 loss: 0.16457472429350775 \n",
      "Epoch:  1\n",
      "1182/1500.0 loss: 0.1644562373665222 \n",
      "Epoch:  1\n",
      "1183/1500.0 loss: 0.1643582682724652 \n",
      "Epoch:  1\n",
      "1184/1500.0 loss: 0.1642468451486924 \n",
      "Epoch:  1\n",
      "1185/1500.0 loss: 0.16414347842326277 \n",
      "Epoch:  1\n",
      "1186/1500.0 loss: 0.1640618655433613 \n",
      "Epoch:  1\n",
      "1187/1500.0 loss: 0.16393676629095566 \n",
      "Epoch:  1\n",
      "1188/1500.0 loss: 0.16382108306194224 \n",
      "Epoch:  1\n",
      "1189/1500.0 loss: 0.1637475597523466 \n",
      "Epoch:  1\n",
      "1190/1500.0 loss: 0.16362622642215563 \n",
      "Epoch:  1\n",
      "1191/1500.0 loss: 0.16352309009854077 \n",
      "Epoch:  1\n",
      "1192/1500.0 loss: 0.16340104601215588 \n",
      "Epoch:  1\n",
      "1193/1500.0 loss: 0.16330113378470418 \n",
      "Epoch:  1\n",
      "1194/1500.0 loss: 0.16319105434523717 \n",
      "Epoch:  1\n",
      "1195/1500.0 loss: 0.16308618171987774 \n",
      "Epoch:  1\n",
      "1196/1500.0 loss: 0.1629653819194787 \n",
      "Epoch:  1\n",
      "1197/1500.0 loss: 0.1628473179760033 \n",
      "Epoch:  1\n",
      "1198/1500.0 loss: 0.16272290041196386 \n",
      "Epoch:  1\n",
      "1199/1500.0 loss: 0.1625992984099624 \n",
      "Epoch:  1\n",
      "1200/1500.0 loss: 0.16249133708136937 \n",
      "Epoch:  1\n",
      "1201/1500.0 loss: 0.16238233452576048 \n",
      "Epoch:  1\n",
      "1202/1500.0 loss: 0.1622639814459859 \n",
      "Epoch:  1\n",
      "1203/1500.0 loss: 0.16214120976605215 \n",
      "Epoch:  1\n",
      "1204/1500.0 loss: 0.16202152673680628 \n",
      "Epoch:  1\n",
      "1205/1500.0 loss: 0.16190842157971133 \n",
      "Epoch:  1\n",
      "1206/1500.0 loss: 0.1617994484250135 \n",
      "Epoch:  1\n",
      "1207/1500.0 loss: 0.1616786515258487 \n",
      "Epoch:  1\n",
      "1208/1500.0 loss: 0.16156704926969617 \n",
      "Epoch:  1\n",
      "1209/1500.0 loss: 0.1614566822582471 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "1210/1500.0 loss: 0.16133717985932955 \n",
      "Epoch:  1\n",
      "1211/1500.0 loss: 0.16121826321885555 \n",
      "Epoch:  1\n",
      "1212/1500.0 loss: 0.16110061345620408 \n",
      "Epoch:  1\n",
      "1213/1500.0 loss: 0.1609814321565483 \n",
      "Epoch:  1\n",
      "1214/1500.0 loss: 0.16086879321469813 \n",
      "Epoch:  1\n",
      "1215/1500.0 loss: 0.16074992025249613 \n",
      "Epoch:  1\n",
      "1216/1500.0 loss: 0.16062968125644897 \n",
      "Epoch:  1\n",
      "1217/1500.0 loss: 0.16052578379169155 \n",
      "Epoch:  1\n",
      "1218/1500.0 loss: 0.16041737633136158 \n",
      "Epoch:  1\n",
      "1219/1500.0 loss: 0.1603174148699971 \n",
      "Epoch:  1\n",
      "1220/1500.0 loss: 0.16019822046142393 \n",
      "Epoch:  1\n",
      "1221/1500.0 loss: 0.1600813757972685 \n",
      "Epoch:  1\n",
      "1222/1500.0 loss: 0.15997339822565154 \n",
      "Epoch:  1\n",
      "1223/1500.0 loss: 0.15985573567237 \n",
      "Epoch:  1\n",
      "1224/1500.0 loss: 0.159738944504334 \n",
      "Epoch:  1\n",
      "1225/1500.0 loss: 0.15962852245321282 \n",
      "Epoch:  1\n",
      "1226/1500.0 loss: 0.15951594662531518 \n",
      "Epoch:  1\n",
      "1227/1500.0 loss: 0.15940222158839967 \n",
      "Epoch:  1\n",
      "1228/1500.0 loss: 0.15928920064094204 \n",
      "Epoch:  1\n",
      "1229/1500.0 loss: 0.15917878237560512 \n",
      "Epoch:  1\n",
      "1230/1500.0 loss: 0.15906290212308702 \n",
      "Epoch:  1\n",
      "1231/1500.0 loss: 0.15894501926543722 \n",
      "Epoch:  1\n",
      "1232/1500.0 loss: 0.15882905589647756 \n",
      "Epoch:  1\n",
      "1233/1500.0 loss: 0.15875397485000123 \n",
      "Epoch:  1\n",
      "1234/1500.0 loss: 0.15864403278827063 \n",
      "Epoch:  1\n",
      "1235/1500.0 loss: 0.15852737977488937 \n",
      "Epoch:  1\n",
      "1236/1500.0 loss: 0.15841400974844985 \n",
      "Epoch:  1\n",
      "1237/1500.0 loss: 0.15829999657251506 \n",
      "Epoch:  1\n",
      "1238/1500.0 loss: 0.15818579696025625 \n",
      "Epoch:  1\n",
      "1239/1500.0 loss: 0.15807548961376833 \n",
      "Epoch:  1\n",
      "1240/1500.0 loss: 0.157957150806477 \n",
      "Epoch:  1\n",
      "1241/1500.0 loss: 0.15784422395115003 \n",
      "Epoch:  1\n",
      "1242/1500.0 loss: 0.15772661432617868 \n",
      "Epoch:  1\n",
      "1243/1500.0 loss: 0.15761203188643794 \n",
      "Epoch:  1\n",
      "1244/1500.0 loss: 0.15749812528386292 \n",
      "Epoch:  1\n",
      "1245/1500.0 loss: 0.15738538074356476 \n",
      "Epoch:  1\n",
      "1246/1500.0 loss: 0.15727585996482477 \n",
      "Epoch:  1\n",
      "1247/1500.0 loss: 0.15716114454269886 \n",
      "Epoch:  1\n",
      "1248/1500.0 loss: 0.1570469422423966 \n",
      "Epoch:  1\n",
      "1249/1500.0 loss: 0.15693128325492145 \n",
      "Epoch:  1\n",
      "1250/1500.0 loss: 0.15681957209305608 \n",
      "Epoch:  1\n",
      "1251/1500.0 loss: 0.15671555860676228 \n",
      "Epoch:  1\n",
      "1252/1500.0 loss: 0.15661023157899226 \n",
      "Epoch:  1\n",
      "1253/1500.0 loss: 0.1565059189516843 \n",
      "Epoch:  1\n",
      "1254/1500.0 loss: 0.15639267703629584 \n",
      "Epoch:  1\n",
      "1255/1500.0 loss: 0.1562804931998668 \n",
      "Epoch:  1\n",
      "1256/1500.0 loss: 0.15616756798692089 \n",
      "Epoch:  1\n",
      "1257/1500.0 loss: 0.15605706787432747 \n",
      "Epoch:  1\n",
      "1258/1500.0 loss: 0.1559547455500548 \n",
      "Epoch:  1\n",
      "1259/1500.0 loss: 0.15583986769770347 \n",
      "Epoch:  1\n",
      "1260/1500.0 loss: 0.15573544960696484 \n",
      "Epoch:  1\n",
      "1261/1500.0 loss: 0.1556230021423694 \n",
      "Epoch:  1\n",
      "1262/1500.0 loss: 0.15550978836380033 \n",
      "Epoch:  1\n",
      "1263/1500.0 loss: 0.15540427208179608 \n",
      "Epoch:  1\n",
      "1264/1500.0 loss: 0.1552940243295589 \n",
      "Epoch:  1\n",
      "1265/1500.0 loss: 0.15518637163723462 \n",
      "Epoch:  1\n",
      "1266/1500.0 loss: 0.15689617122325755 \n",
      "Epoch:  1\n",
      "1267/1500.0 loss: 0.15678444052297233 \n",
      "Epoch:  1\n",
      "1268/1500.0 loss: 0.15667811116252103 \n",
      "Epoch:  1\n",
      "1269/1500.0 loss: 0.15656661938171923 \n",
      "Epoch:  1\n",
      "1270/1500.0 loss: 0.15645333161221467 \n",
      "Epoch:  1\n",
      "1271/1500.0 loss: 0.15635130866416055 \n",
      "Epoch:  1\n",
      "1272/1500.0 loss: 0.15625728397335323 \n",
      "Epoch:  1\n",
      "1273/1500.0 loss: 0.15614815764757842 \n",
      "Epoch:  1\n",
      "1274/1500.0 loss: 0.15757581242962795 \n",
      "Epoch:  1\n",
      "1275/1500.0 loss: 0.15746737663272103 \n",
      "Epoch:  1\n",
      "1276/1500.0 loss: 0.15735924728112638 \n",
      "Epoch:  1\n",
      "1277/1500.0 loss: 0.15725184993596866 \n",
      "Epoch:  1\n",
      "1278/1500.0 loss: 0.15713958380535606 \n",
      "Epoch:  1\n",
      "1279/1500.0 loss: 0.1570278094870446 \n",
      "Epoch:  1\n",
      "1280/1500.0 loss: 0.15692018076070788 \n",
      "Epoch:  1\n",
      "1281/1500.0 loss: 0.15681194484033353 \n",
      "Epoch:  1\n",
      "1282/1500.0 loss: 0.15670193275124625 \n",
      "Epoch:  1\n",
      "1283/1500.0 loss: 0.15661421838953418 \n",
      "Epoch:  1\n",
      "1284/1500.0 loss: 0.15650416981022994 \n",
      "Epoch:  1\n",
      "1285/1500.0 loss: 0.15640437625954 \n",
      "Epoch:  1\n",
      "1286/1500.0 loss: 0.15629943308913277 \n",
      "Epoch:  1\n",
      "1287/1500.0 loss: 0.15619078788382829 \n",
      "Epoch:  1\n",
      "1288/1500.0 loss: 0.15610830819550714 \n",
      "Epoch:  1\n",
      "1289/1500.0 loss: 0.1560048707313258 \n",
      "Epoch:  1\n",
      "1290/1500.0 loss: 0.15590081072255887 \n",
      "Epoch:  1\n",
      "1291/1500.0 loss: 0.1557966340744101 \n",
      "Epoch:  1\n",
      "1292/1500.0 loss: 0.1557180699622237 \n",
      "Epoch:  1\n",
      "1293/1500.0 loss: 0.1556134769438235 \n",
      "Epoch:  1\n",
      "1294/1500.0 loss: 0.15550757670652798 \n",
      "Epoch:  1\n",
      "1295/1500.0 loss: 0.15540206588065988 \n",
      "Epoch:  1\n",
      "1296/1500.0 loss: 0.15529277799155566 \n",
      "Epoch:  1\n",
      "1297/1500.0 loss: 0.15518543215680908 \n",
      "Epoch:  1\n",
      "1298/1500.0 loss: 0.1550825731255246 \n",
      "Epoch:  1\n",
      "1299/1500.0 loss: 0.15497503220820083 \n",
      "Epoch:  1\n",
      "1300/1500.0 loss: 0.15487748684345828 \n",
      "Epoch:  1\n",
      "1301/1500.0 loss: 0.15477264952129138 \n",
      "Epoch:  1\n",
      "1302/1500.0 loss: 0.15467014353356381 \n",
      "Epoch:  1\n",
      "1303/1500.0 loss: 0.1545610796328794 \n",
      "Epoch:  1\n",
      "1304/1500.0 loss: 0.154453480909525 \n",
      "Epoch:  1\n",
      "1305/1500.0 loss: 0.15434980504200502 \n",
      "Epoch:  1\n",
      "1306/1500.0 loss: 0.1542477292637893 \n",
      "Epoch:  1\n",
      "1307/1500.0 loss: 0.15417011088794183 \n",
      "Epoch:  1\n",
      "1308/1500.0 loss: 0.15406547823381547 \n",
      "Epoch:  1\n",
      "1309/1500.0 loss: 0.15395904919061498 \n",
      "Epoch:  1\n",
      "1310/1500.0 loss: 0.15386419464399986 \n",
      "Epoch:  1\n",
      "1311/1500.0 loss: 0.1537582931192535 \n",
      "Epoch:  1\n",
      "1312/1500.0 loss: 0.15368775893655312 \n",
      "Epoch:  1\n",
      "1313/1500.0 loss: 0.15358567687567987 \n",
      "Epoch:  1\n",
      "1314/1500.0 loss: 0.153482041192797 \n",
      "Epoch:  1\n",
      "1315/1500.0 loss: 0.15337240074741396 \n",
      "Epoch:  1\n",
      "1316/1500.0 loss: 0.15327514803649445 \n",
      "Epoch:  1\n",
      "1317/1500.0 loss: 0.15316712734754423 \n",
      "Epoch:  1\n",
      "1318/1500.0 loss: 0.1530599862102693 \n",
      "Epoch:  1\n",
      "1319/1500.0 loss: 0.1529608368661932 \n",
      "Epoch:  1\n",
      "1320/1500.0 loss: 0.1528575695207925 \n",
      "Epoch:  1\n",
      "1321/1500.0 loss: 0.15274977026107114 \n",
      "Epoch:  1\n",
      "1322/1500.0 loss: 0.15264592270591407 \n",
      "Epoch:  1\n",
      "1323/1500.0 loss: 0.1525533138324149 \n",
      "Epoch:  1\n",
      "1324/1500.0 loss: 0.15245557276707775 \n",
      "Epoch:  1\n",
      "1325/1500.0 loss: 0.15235329758611874 \n",
      "Epoch:  1\n",
      "1326/1500.0 loss: 0.1522534923135291 \n",
      "Epoch:  1\n",
      "1327/1500.0 loss: 0.15214932871581313 \n",
      "Epoch:  1\n",
      "1328/1500.0 loss: 0.1520451052924457 \n",
      "Epoch:  1\n",
      "1329/1500.0 loss: 0.15194351237225243 \n",
      "Epoch:  1\n",
      "1330/1500.0 loss: 0.15184067600007167 \n",
      "Epoch:  1\n",
      "1331/1500.0 loss: 0.15173605256490186 \n",
      "Epoch:  1\n",
      "1332/1500.0 loss: 0.15168216511319318 \n",
      "Epoch:  1\n",
      "1333/1500.0 loss: 0.15158281416452113 \n",
      "Epoch:  1\n",
      "1334/1500.0 loss: 0.15148261034937946 \n",
      "Epoch:  1\n",
      "1335/1500.0 loss: 0.15137978069118954 \n",
      "Epoch:  1\n",
      "1336/1500.0 loss: 0.15128355305335395 \n",
      "Epoch:  1\n",
      "1337/1500.0 loss: 0.15117984439659812 \n",
      "Epoch:  1\n",
      "1338/1500.0 loss: 0.15108180898252133 \n",
      "Epoch:  1\n",
      "1339/1500.0 loss: 0.15097932747370604 \n",
      "Epoch:  1\n",
      "1340/1500.0 loss: 0.15087951864563845 \n",
      "Epoch:  1\n",
      "1341/1500.0 loss: 0.1507769581277462 \n",
      "Epoch:  1\n",
      "1342/1500.0 loss: 0.15067757694404335 \n",
      "Epoch:  1\n",
      "1343/1500.0 loss: 0.15057509045609982 \n",
      "Epoch:  1\n",
      "1344/1500.0 loss: 0.1504736043325864 \n",
      "Epoch:  1\n",
      "1345/1500.0 loss: 0.1503741308129261 \n",
      "Epoch:  1\n",
      "1346/1500.0 loss: 0.15027827387654902 \n",
      "Epoch:  1\n",
      "1347/1500.0 loss: 0.1501765633754996 \n",
      "Epoch:  1\n",
      "1348/1500.0 loss: 0.15007855788389673 \n",
      "Epoch:  1\n",
      "1349/1500.0 loss: 0.14997689896090716 \n",
      "Epoch:  1\n",
      "1350/1500.0 loss: 0.14987359420471527 \n",
      "Epoch:  1\n",
      "1351/1500.0 loss: 0.14977610640065225 \n",
      "Epoch:  1\n",
      "1352/1500.0 loss: 0.14967715359621261 \n",
      "Epoch:  1\n",
      "1353/1500.0 loss: 0.14957706562891337 \n",
      "Epoch:  1\n",
      "1354/1500.0 loss: 0.14948227562188993 \n",
      "Epoch:  1\n",
      "1355/1500.0 loss: 0.1493863282844721 \n",
      "Epoch:  1\n",
      "1356/1500.0 loss: 0.1492938291749525 \n",
      "Epoch:  1\n",
      "1357/1500.0 loss: 0.14920055838192048 \n",
      "Epoch:  1\n",
      "1358/1500.0 loss: 0.14909969378849375 \n",
      "Epoch:  1\n",
      "1359/1500.0 loss: 0.14900028473656515 \n",
      "Epoch:  1\n",
      "1360/1500.0 loss: 0.14890017730377555 \n",
      "Epoch:  1\n",
      "1361/1500.0 loss: 0.14880550233168574 \n",
      "Epoch:  1\n",
      "1362/1500.0 loss: 0.1487073822395216 \n",
      "Epoch:  1\n",
      "1363/1500.0 loss: 0.14861058721611073 \n",
      "Epoch:  1\n",
      "1364/1500.0 loss: 0.14851736962699738 \n",
      "Epoch:  1\n",
      "1365/1500.0 loss: 0.1484216973546887 \n",
      "Epoch:  1\n",
      "1366/1500.0 loss: 0.14832446710005587 \n",
      "Epoch:  1\n",
      "1367/1500.0 loss: 0.14822706076240286 \n",
      "Epoch:  1\n",
      "1368/1500.0 loss: 0.14813083227263957 \n",
      "Epoch:  1\n",
      "1369/1500.0 loss: 0.1480401295842263 \n",
      "Epoch:  1\n",
      "1370/1500.0 loss: 0.14793888778635658 \n",
      "Epoch:  1\n",
      "1371/1500.0 loss: 0.14784178480372898 \n",
      "Epoch:  1\n",
      "1372/1500.0 loss: 0.14774440649017767 \n",
      "Epoch:  1\n",
      "1373/1500.0 loss: 0.1476480067196523 \n",
      "Epoch:  1\n",
      "1374/1500.0 loss: 0.14754995867745443 \n",
      "Epoch:  1\n",
      "1375/1500.0 loss: 0.14745281124961301 \n",
      "Epoch:  1\n",
      "1376/1500.0 loss: 0.147356034988996 \n",
      "Epoch:  1\n",
      "1377/1500.0 loss: 0.14725851358748507 \n",
      "Epoch:  1\n",
      "1378/1500.0 loss: 0.14716496122521472 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "1379/1500.0 loss: 0.14708865831633086 \n",
      "Epoch:  1\n",
      "1380/1500.0 loss: 0.14699485701435314 \n",
      "Epoch:  1\n",
      "1381/1500.0 loss: 0.14690558006582638 \n",
      "Epoch:  1\n",
      "1382/1500.0 loss: 0.14680947514489262 \n",
      "Epoch:  1\n",
      "1383/1500.0 loss: 0.14672135787671486 \n",
      "Epoch:  1\n",
      "1384/1500.0 loss: 0.1466289599584113 \n",
      "Epoch:  1\n",
      "1385/1500.0 loss: 0.14653311638244862 \n",
      "Epoch:  1\n",
      "1386/1500.0 loss: 0.14643574457900316 \n",
      "Epoch:  1\n",
      "1387/1500.0 loss: 0.14634189439966996 \n",
      "Epoch:  1\n",
      "1388/1500.0 loss: 0.14624920971570918 \n",
      "Epoch:  1\n",
      "1389/1500.0 loss: 0.14615902780159878 \n",
      "Epoch:  1\n",
      "1390/1500.0 loss: 0.146063942696543 \n",
      "Epoch:  1\n",
      "1391/1500.0 loss: 0.1459699334013383 \n",
      "Epoch:  1\n",
      "1392/1500.0 loss: 0.14587515804913945 \n",
      "Epoch:  1\n",
      "1393/1500.0 loss: 0.14578017856193495 \n",
      "Epoch:  1\n",
      "1394/1500.0 loss: 0.14568951418055856 \n",
      "Epoch:  1\n",
      "1395/1500.0 loss: 0.14559602577847702 \n",
      "Epoch:  1\n",
      "1396/1500.0 loss: 0.1455064501690711 \n",
      "Epoch:  1\n",
      "1397/1500.0 loss: 0.14540993258255788 \n",
      "Epoch:  1\n",
      "1398/1500.0 loss: 0.1453205482998305 \n",
      "Epoch:  1\n",
      "1399/1500.0 loss: 0.14522929196379014 \n",
      "Epoch:  1\n",
      "1400/1500.0 loss: 0.14514047182633738 \n",
      "Epoch:  1\n",
      "1401/1500.0 loss: 0.1450523541185383 \n",
      "Epoch:  1\n",
      "1402/1500.0 loss: 0.1449563749378822 \n",
      "Epoch:  1\n",
      "1403/1500.0 loss: 0.1448637721244182 \n",
      "Epoch:  1\n",
      "1404/1500.0 loss: 0.14477766527996475 \n",
      "Epoch:  1\n",
      "1405/1500.0 loss: 0.1446873376279762 \n",
      "Epoch:  1\n",
      "1406/1500.0 loss: 0.1446044485765829 \n",
      "Epoch:  1\n",
      "1407/1500.0 loss: 0.14450982832072026 \n",
      "Epoch:  1\n",
      "1408/1500.0 loss: 0.14441927587263143 \n",
      "Epoch:  1\n",
      "1409/1500.0 loss: 0.1443315232628362 \n",
      "Epoch:  1\n",
      "1410/1500.0 loss: 0.14423799729944964 \n",
      "Epoch:  1\n",
      "1411/1500.0 loss: 0.14415127372701597 \n",
      "Epoch:  1\n",
      "1412/1500.0 loss: 0.14406023458337117 \n",
      "Epoch:  1\n",
      "1413/1500.0 loss: 0.14396854682234042 \n",
      "Epoch:  1\n",
      "1414/1500.0 loss: 0.14387570926031037 \n",
      "Epoch:  1\n",
      "1415/1500.0 loss: 0.1437818851206178 \n",
      "Epoch:  1\n",
      "1416/1500.0 loss: 0.143691463627305 \n",
      "Epoch:  1\n",
      "1417/1500.0 loss: 0.14361494793904728 \n",
      "Epoch:  1\n",
      "1418/1500.0 loss: 0.1435236832457762 \n",
      "Epoch:  1\n",
      "1419/1500.0 loss: 0.1434351611954593 \n",
      "Epoch:  1\n",
      "1420/1500.0 loss: 0.14334699264376893 \n",
      "Epoch:  1\n",
      "1421/1500.0 loss: 0.1432518636245862 \n",
      "Epoch:  1\n",
      "1422/1500.0 loss: 0.14315960884358647 \n",
      "Epoch:  1\n",
      "1423/1500.0 loss: 0.14306898860802372 \n",
      "Epoch:  1\n",
      "1424/1500.0 loss: 0.14297801257552284 \n",
      "Epoch:  1\n",
      "1425/1500.0 loss: 0.14288737437835416 \n",
      "Epoch:  1\n",
      "1426/1500.0 loss: 0.1428085104278442 \n",
      "Epoch:  1\n",
      "1427/1500.0 loss: 0.14271658421324498 \n",
      "Epoch:  1\n",
      "1428/1500.0 loss: 0.14262545462293671 \n",
      "Epoch:  1\n",
      "1429/1500.0 loss: 0.14254029128257628 \n",
      "Epoch:  1\n",
      "1430/1500.0 loss: 0.14245185086270631 \n",
      "Epoch:  1\n",
      "1431/1500.0 loss: 0.14236284879897332 \n",
      "Epoch:  1\n",
      "1432/1500.0 loss: 0.14227732368637674 \n",
      "Epoch:  1\n",
      "1433/1500.0 loss: 0.1421857739024571 \n",
      "Epoch:  1\n",
      "1434/1500.0 loss: 0.14209870362543997 \n",
      "Epoch:  1\n",
      "1435/1500.0 loss: 0.14201238791946022 \n",
      "Epoch:  1\n",
      "1436/1500.0 loss: 0.1419222188326702 \n",
      "Epoch:  1\n",
      "1437/1500.0 loss: 0.141842038675065 \n",
      "Epoch:  1\n",
      "1438/1500.0 loss: 0.1417549224382705 \n",
      "Epoch:  1\n",
      "1439/1500.0 loss: 0.14166603105453154 \n",
      "Epoch:  1\n",
      "1440/1500.0 loss: 0.1415787919164014 \n",
      "Epoch:  1\n",
      "1441/1500.0 loss: 0.14148967735141246 \n",
      "Epoch:  1\n",
      "1442/1500.0 loss: 0.141403739885327 \n",
      "Epoch:  1\n",
      "1443/1500.0 loss: 0.14131802747508515 \n",
      "Epoch:  1\n",
      "1444/1500.0 loss: 0.14122684703347077 \n",
      "Epoch:  1\n",
      "1445/1500.0 loss: 0.14113988578358194 \n",
      "Epoch:  1\n",
      "1446/1500.0 loss: 0.14107681085042134 \n",
      "Epoch:  1\n",
      "1447/1500.0 loss: 0.14099149321121016 \n",
      "Epoch:  1\n",
      "1448/1500.0 loss: 0.1409036051661928 \n",
      "Epoch:  1\n",
      "1449/1500.0 loss: 0.14081614157120728 \n",
      "Epoch:  1\n",
      "1450/1500.0 loss: 0.14073008371787923 \n",
      "Epoch:  1\n",
      "1451/1500.0 loss: 0.1406454022257966 \n",
      "Epoch:  1\n",
      "1452/1500.0 loss: 0.1405619253485841 \n",
      "Epoch:  1\n",
      "1453/1500.0 loss: 0.14047368626434362 \n",
      "Epoch:  1\n",
      "1454/1500.0 loss: 0.14038499475447172 \n",
      "Epoch:  1\n",
      "1455/1500.0 loss: 0.14029750857466403 \n",
      "Epoch:  1\n",
      "1456/1500.0 loss: 0.14021552736470164 \n",
      "Epoch:  1\n",
      "1457/1500.0 loss: 0.14013125558111647 \n",
      "Epoch:  1\n",
      "1458/1500.0 loss: 0.14004491445831213 \n",
      "Epoch:  1\n",
      "1459/1500.0 loss: 0.13996578320950168 \n",
      "Epoch:  1\n",
      "1460/1500.0 loss: 0.13987883650184615 \n",
      "Epoch:  1\n",
      "1461/1500.0 loss: 0.13979380268465966 \n",
      "Epoch:  1\n",
      "1462/1500.0 loss: 0.13971637510863258 \n",
      "Epoch:  1\n",
      "1463/1500.0 loss: 0.1396317360082977 \n",
      "Epoch:  1\n",
      "1464/1500.0 loss: 0.139543802179269 \n",
      "Epoch:  1\n",
      "1465/1500.0 loss: 0.13945873771536216 \n",
      "Epoch:  1\n",
      "1466/1500.0 loss: 0.1393708954130356 \n",
      "Epoch:  1\n",
      "1467/1500.0 loss: 0.13928943557400836 \n",
      "Epoch:  1\n",
      "1468/1500.0 loss: 0.13920454150401793 \n",
      "Epoch:  1\n",
      "1469/1500.0 loss: 0.13911785042534272 \n",
      "Epoch:  1\n",
      "1470/1500.0 loss: 0.13903071120556096 \n",
      "Epoch:  1\n",
      "1471/1500.0 loss: 0.13895117861292142 \n",
      "Epoch:  1\n",
      "1472/1500.0 loss: 0.1388701333898927 \n",
      "Epoch:  1\n",
      "1473/1500.0 loss: 0.13878315935553312 \n",
      "Epoch:  1\n",
      "1474/1500.0 loss: 0.1386964773898155 \n",
      "Epoch:  1\n",
      "1475/1500.0 loss: 0.13861286438191386 \n",
      "Epoch:  1\n",
      "1476/1500.0 loss: 0.13852975718215482 \n",
      "Epoch:  1\n",
      "1477/1500.0 loss: 0.13844511582653501 \n",
      "Epoch:  1\n",
      "1478/1500.0 loss: 0.1383625010766487 \n",
      "Epoch:  1\n",
      "1479/1500.0 loss: 0.1382783269604064 \n",
      "Epoch:  1\n",
      "1480/1500.0 loss: 0.13819194862154954 \n",
      "Epoch:  1\n",
      "1481/1500.0 loss: 0.1381072168026054 \n",
      "Epoch:  1\n",
      "1482/1500.0 loss: 0.13802131586937347 \n",
      "Epoch:  1\n",
      "1483/1500.0 loss: 0.1379358641755569 \n",
      "Epoch:  1\n",
      "1484/1500.0 loss: 0.13785090504232983 \n",
      "Epoch:  1\n",
      "1485/1500.0 loss: 0.13777170515359752 \n",
      "Epoch:  1\n",
      "1486/1500.0 loss: 0.13768812166445493 \n",
      "Epoch:  1\n",
      "1487/1500.0 loss: 0.1376119860571869 \n",
      "Epoch:  1\n",
      "1488/1500.0 loss: 0.13760790569036 \n",
      "Epoch:  1\n",
      "1489/1500.0 loss: 0.1375238617950888 \n",
      "Epoch:  1\n",
      "1490/1500.0 loss: 0.1374559781022525 \n",
      "Epoch:  1\n",
      "1491/1500.0 loss: 0.13737271454724564 \n",
      "Epoch:  1\n",
      "1492/1500.0 loss: 0.1372919103601038 \n",
      "Epoch:  1\n",
      "1493/1500.0 loss: 0.13721331913358317 \n",
      "Epoch:  1\n",
      "1494/1500.0 loss: 0.1371300520001596 \n",
      "Epoch:  1\n",
      "1495/1500.0 loss: 0.13704447145573795 \n",
      "Epoch:  1\n",
      "1496/1500.0 loss: 0.1369609523573287 \n",
      "Epoch:  1\n",
      "1497/1500.0 loss: 0.136878339494162 \n",
      "Epoch:  1\n",
      "1498/1500.0 loss: 0.13679836481794705 \n",
      "Epoch:  1\n",
      "1499/1500.0 loss: 0.13671460085175932 \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "bert_clf = BertBinaryClassifier()\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        probas = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       249\n",
      "           1       1.00      0.99      0.99       251\n",
      "\n",
      "    accuracy                           0.99       500\n",
      "   macro avg       0.99      0.99      0.99       500\n",
      "weighted avg       0.99      0.99      0.99       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss() #binomial cross entropy loss\n",
    "        loss = loss_func(logits, labels) \n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "        \n",
    "print(classification_report(test_y, bert_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRECISION = TRUE POS / TRUE POS + FALSE POS\n",
    "RECALL = TRUE POS / TRUE POS + FALSE NEG\n",
    "F1 = (2 * RECALL * PRECISION) / ( RECALL + PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
