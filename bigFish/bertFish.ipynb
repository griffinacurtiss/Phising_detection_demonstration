{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 3234\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_fraud.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE, SET LENGTH: 13265\n"
     ]
    }
   ],
   "source": [
    "%run ./seg_normal.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('fraud.txt', 'r')\n",
    "f2 = open('enron.txt', 'r')\n",
    "\n",
    "corpus_one = [item for item in f1]\n",
    "corpus_two = [item for item in f2]\n",
    "\n",
    "fraud_set = split_set(corpus_one)\n",
    "norm_set = split_enron_set(corpus_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_set = fraud_set[:6]\n",
    "norm_set = norm_set[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(fraud, norm):\n",
    "    new_set = []\n",
    "    for item in fraud:\n",
    "        t = (item, 'fraud')\n",
    "        new_set.append(t)\n",
    "    for item in norm:\n",
    "        t = (item, 'norm')\n",
    "        new_set.append(t)\n",
    "    return new_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = label(fraud_set,norm_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NECESSARY IMPORTS:\n",
    "#torch\n",
    "#pytorch-pretrained-bert\n",
    "#torchnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0      1\n",
      "0  Return-Path: <james_ngola2002@maktoob.com>\\nX-...  fraud\n",
      "1  Return-Path: <bensul2004nng@spinfinder.com>\\nX...  fraud\n",
      "2  \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
      "3  \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
      "4  \\nDear sir, \\n \\nIt is with a heart full of ho...  fraud\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = g\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'fraud': 6, 'norm': 6})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df[1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: \"text\", 1: \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('pos', 'fraud')\n",
    "df = df.replace('neg', 'norm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Return-Path: &lt;james_ngola2002@maktoob.com&gt;\\nX-...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Return-Path: &lt;bensul2004nng@spinfinder.com&gt;\\nX...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\nDear sir, \\n \\nIt is with a heart full of ho...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   type\n",
       "0  Return-Path: <james_ngola2002@maktoob.com>\\nX-...  fraud\n",
       "1  Return-Path: <bensul2004nng@spinfinder.com>\\nX...  fraud\n",
       "2  \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
       "3  \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
       "4  \\nDear sir, \\n \\nIt is with a heart full of ho...  fraud"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df[df['type'] == 'fraud'] \n",
    "df_statire = df[df['type'] == 'norm'] \n",
    "df_statire = df_statire.sample(n=len(df_fake))\n",
    "df = df_statire.append(df_fake)\n",
    "df = df.sample(frac=1, random_state = 24).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.head(6)\n",
    "test_data = df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\nATTENTION:                                  ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\nRandy,\\n\\n Can you send me a schedule of the...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nDear sir, \\n \\nIt is with a heart full of ho...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"file\",\"message\"\\n\"allen-p/_sent_mail/1.\",\"Mes...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   type\n",
       "0  \\nATTENTION:                                  ...  fraud\n",
       "1  \\nRandy,\\n\\n Can you send me a schedule of the...   norm\n",
       "2  \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
       "3  \\nDear sir, \\n \\nIt is with a heart full of ho...  fraud\n",
       "4  \"file\",\"message\"\\n\"allen-p/_sent_mail/1.\",\"Mes...   norm"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>\\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>\\nHere is our forecast\\n\\n \"\\n\"allen-p/_sent_m...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Return-Path: &lt;bensul2004nng@spinfinder.com&gt;\\nX...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>\\ntest successful.  way to go!!!\"\\n\"allen-p/_s...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>\\nLet's shoot for Tuesday at 11:45.  \"\\n\"allen...</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   type\n",
       "6   \\nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...  fraud\n",
       "7   \\nHere is our forecast\\n\\n \"\\n\"allen-p/_sent_m...   norm\n",
       "8   Return-Path: <bensul2004nng@spinfinder.com>\\nX...  fraud\n",
       "9   \\ntest successful.  way to go!!!\"\\n\"allen-p/_s...   norm\n",
       "10  \\nLet's shoot for Tuesday at 11:45.  \"\\n\"allen...   norm"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [{'text': text, 'type': type_data } for text in list(train_data['text']) for type_data in list(train_data['type'])]\n",
    "test_data = [{'text': text, 'type': type_data } for text in list(test_data['text']) for type_data in list(test_data['type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
    "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "<class 'tuple'>\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "fraud\n",
      "norm\n",
      "fraud\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(type(train_labels))\n",
    "for item in train_labels:(print(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "<class 'tuple'>\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "fraud\n",
      "norm\n",
      "norm\n",
      "norm\n"
     ]
    }
   ],
   "source": [
    "print(len(test_labels))\n",
    "print(type(test_labels))\n",
    "for item in test_labels: print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "t1 = []\n",
    "t2 = []\n",
    "\n",
    "for item in train_labels:\n",
    "    if str(item) == 'fraud': t1.append(1)\n",
    "    else: t1.append(0)    \n",
    "\n",
    "        \n",
    "\n",
    "for item in test_labels:\n",
    "    if str(item) == 'fraud': t2.append(1)\n",
    "    else: t2.append(0)        \n",
    "\n",
    "#train_y_step = np.array(train_labels) == 'fake'\n",
    "#test_y_step = np.array(test_labels) == 'fake'\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(len(train_y_step)):\n",
    "    #train_y.append(int(train_y_step[i]))\n",
    "#for i in range(len(test_y_step)):\n",
    "    #test_y.append(int(test_y_step[i]))\n",
    "    \n",
    "train_y = np.array(t1)\n",
    "test_y = np.array(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for item in train_y: print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for item in test_y: print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "    \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=1)\n",
    "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATEMENT BELOW ITERATES THROUGH EACH ITEM IN THE TRAINING DATASET AT ONE EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/36.0 loss: 0.7049091458320618 \n",
      "Epoch:  1\n",
      "1/36.0 loss: 0.7767441272735596 \n",
      "Epoch:  1\n",
      "2/36.0 loss: 0.7959642012914022 \n",
      "Epoch:  1\n",
      "3/36.0 loss: 0.7931198626756668 \n",
      "Epoch:  1\n",
      "4/36.0 loss: 0.7663469314575195 \n",
      "Epoch:  1\n",
      "5/36.0 loss: 0.7504710058371226 \n",
      "Epoch:  1\n",
      "6/36.0 loss: 0.7454165816307068 \n",
      "Epoch:  1\n",
      "7/36.0 loss: 0.7371055707335472 \n",
      "Epoch:  1\n",
      "8/36.0 loss: 0.7291107641326057 \n",
      "Epoch:  1\n",
      "9/36.0 loss: 0.7330771625041962 \n",
      "Epoch:  1\n",
      "10/36.0 loss: 0.7316584261980924 \n",
      "Epoch:  1\n",
      "11/36.0 loss: 0.7363427529732386 \n",
      "Epoch:  1\n",
      "12/36.0 loss: 0.7330259405649625 \n",
      "Epoch:  1\n",
      "13/36.0 loss: 0.7447047914777484 \n",
      "Epoch:  1\n",
      "14/36.0 loss: 0.7438952883084615 \n",
      "Epoch:  1\n",
      "15/36.0 loss: 0.7427257150411606 \n",
      "Epoch:  1\n",
      "16/36.0 loss: 0.7464038379052106 \n",
      "Epoch:  1\n",
      "17/36.0 loss: 0.7456305060121748 \n",
      "Epoch:  1\n",
      "18/36.0 loss: 0.7492861214436983 \n",
      "Epoch:  1\n",
      "19/36.0 loss: 0.7436093747615814 \n",
      "Epoch:  1\n",
      "20/36.0 loss: 0.7414100964864095 \n",
      "Epoch:  1\n",
      "21/36.0 loss: 0.7394105819138613 \n",
      "Epoch:  1\n",
      "22/36.0 loss: 0.7381922654483629 \n",
      "Epoch:  1\n",
      "23/36.0 loss: 0.7342447464664777 \n",
      "Epoch:  1\n",
      "24/36.0 loss: 0.7341620397567749 \n",
      "Epoch:  1\n",
      "25/36.0 loss: 0.7365848995172061 \n",
      "Epoch:  1\n",
      "26/36.0 loss: 0.7391086507726599 \n",
      "Epoch:  1\n",
      "27/36.0 loss: 0.7331176378897258 \n",
      "Epoch:  1\n",
      "28/36.0 loss: 0.7302672123086864 \n",
      "Epoch:  1\n",
      "29/36.0 loss: 0.731987722714742 \n",
      "Epoch:  1\n",
      "30/36.0 loss: 0.7301493229404572 \n",
      "Epoch:  1\n",
      "31/36.0 loss: 0.7254376597702503 \n",
      "Epoch:  1\n",
      "32/36.0 loss: 0.7253685268488798 \n",
      "Epoch:  1\n",
      "33/36.0 loss: 0.7232898631516624 \n",
      "Epoch:  1\n",
      "34/36.0 loss: 0.7188647815159389 \n",
      "Epoch:  1\n",
      "35/36.0 loss: 0.7145059953133265 \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "bert_clf = BertBinaryClassifier()\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        probas = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.33      1.00      0.50        12\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        36\n",
      "   macro avg       0.17      0.50      0.25        36\n",
      "weighted avg       0.11      0.33      0.17        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcurtiss/venv/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(logits, labels)\n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "        \n",
    "print(classification_report(test_y, bert_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
